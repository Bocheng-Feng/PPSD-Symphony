{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a75d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy.constants import G\n",
    "from astropy import units as u\n",
    "from scipy.integrate import quad\n",
    "import symlib\n",
    "import os\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.optimize import curve_fit   \n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "base_dir = \"/Users/fengbocheng/Projects/Symphony-PPSD\"\n",
    "suite_names = [\"SymphonyLMC\", \"SymphonyMilkyWay\", \"SymphonyGroup\", \"SymphonyLCluster\", \"SymphonyCluster\"]\n",
    "sim_colors = {\n",
    "        \"SymphonyLMC\": sns.color_palette(\"colorblind\")[4],\n",
    "        \"SymphonyMilkyWay\": sns.color_palette(\"colorblind\")[0],\n",
    "        \"SymphonyGroup\": sns.color_palette(\"colorblind\")[2],\n",
    "        \"SymphonyLCluster\": sns.color_palette(\"colorblind\")[1],\n",
    "        \"SymphonyCluster\": sns.color_palette(\"colorblind\")[3],\n",
    "    }\n",
    "sim_names = {\n",
    "        \"SymphonyLMC\": \"LMC\",\n",
    "        \"SymphonyMilkyWay\": \"Milky~Way\",\n",
    "        \"SymphonyGroup\": \"Group\",\n",
    "        \"SymphonyLCluster\": \"L-Cluster\",\n",
    "        \"SymphonyCluster\": \"Cluster\",\n",
    "    }\n",
    "mean_cvir = {\n",
    "    \"SymphonyLMC\": 12.2,\n",
    "    \"SymphonyMilkyWay\": 10.8,\n",
    "    \"SymphonyGroup\": 9.0,\n",
    "    \"SymphonyLCluster\": 5.0,\n",
    "    \"SymphonyCluster\": 5.6,\n",
    "}\n",
    "out_dir = os.path.join(base_dir, \"output\", \"FIGURE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e98301",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = 1 \n",
    "\n",
    "def compute_eta_from_scaled_profiles(r, rho, m_enc, sigma_r, sigma_tan):\n",
    "    dr = np.gradient(r)\n",
    "    vol = 4 * np.pi * r**2\n",
    "\n",
    "    sigma2_tot = sigma_r**2 + sigma_tan**2\n",
    "\n",
    "    # Scaled kinetic energy\n",
    "    integrand_K = 0.5 * rho * sigma2_tot * vol\n",
    "    K = np.sum(integrand_K * dr)\n",
    "\n",
    "    # Scaled potential energy\n",
    "    integrand_U = -m_enc * rho / r * vol\n",
    "    U = np.sum(integrand_U * dr)\n",
    "\n",
    "    if U >= 0 or K <= 0:\n",
    "        return np.nan\n",
    "    return 2 * K / abs(U)\n",
    "\n",
    "def compare_normalized_jeans_deviation_vs_virial_ratio():\n",
    "\n",
    "    delta_J_list = []\n",
    "    eta_list     = []\n",
    "    mass_list    = []\n",
    "\n",
    "    # 1) Gather raw δJ, η, and M_vir for all halos\n",
    "    for suite in suite_names:\n",
    "        density_dir = os.path.join(base_dir, \"output\", suite, \"density_profiles\")\n",
    "        velocity_dir = os.path.join(base_dir, \"output\", suite, \"velocity_profiles\")\n",
    "        mass_dir    = os.path.join(base_dir, \"output\", suite, \"mass_profiles\")\n",
    "        jeans_path  = os.path.join(base_dir, \"output\", suite, \"jeans_deviation_total.csv\")\n",
    "        mass_path   = os.path.join(base_dir, \"output\", suite, \"halo_mass.csv\")\n",
    "\n",
    "        # load δJ_tot per halo\n",
    "        df_jeans = pd.read_csv(jeans_path)\n",
    "        jeans_dict = dict(zip(df_jeans[\"halo_id\"],\n",
    "                              pd.to_numeric(df_jeans[\"delta_J_tot\"], errors='coerce')))\n",
    "        # load M_vir per halo\n",
    "        df_mass = pd.read_csv(mass_path)\n",
    "        mass_dict = dict(zip(df_mass[\"halo_id\"],\n",
    "                             pd.to_numeric(df_mass[\"mvir\"], errors='coerce')))\n",
    "\n",
    "        # loop through each halo’s density file to compute η\n",
    "        for fname in sorted(os.listdir(density_dir)):\n",
    "            if not fname.endswith(\".csv\"):\n",
    "                continue\n",
    "            try:\n",
    "                halo_id = int(fname.split(\"_\")[1])\n",
    "                if halo_id not in jeans_dict or halo_id not in mass_dict:\n",
    "                    continue\n",
    "\n",
    "                # read profiles\n",
    "                df_rho = pd.read_csv(os.path.join(density_dir, fname))\n",
    "                df_vel = pd.read_csv(os.path.join(velocity_dir, fname))\n",
    "                df_menc= pd.read_csv(os.path.join(mass_dir, fname))\n",
    "\n",
    "                r      = pd.to_numeric(df_rho[\"r_scaled\"], errors='coerce').values\n",
    "                rho    = pd.to_numeric(df_rho[\"rho_scaled\"], errors='coerce').values\n",
    "                m_enc  = pd.to_numeric(df_menc[\"m_scaled\"], errors='coerce').values\n",
    "                sigma_r   = pd.to_numeric(df_vel[\"sigma_rad_scaled\"], errors='coerce').values\n",
    "                sigma_tan = pd.to_numeric(df_vel[\"sigma_tan_scaled\"], errors='coerce').values\n",
    "\n",
    "                # require matching lengths\n",
    "                if not (len(r)==len(rho)==len(m_enc)==len(sigma_r)==len(sigma_tan)):\n",
    "                    continue\n",
    "\n",
    "                # compute virial ratio η = 2K/|U|\n",
    "                eta = compute_eta_from_scaled_profiles(r, rho, m_enc, sigma_r, sigma_tan)\n",
    "                delta_J = jeans_dict[halo_id]\n",
    "                mvir    = mass_dict[halo_id]\n",
    "\n",
    "                if np.isfinite(eta) and np.isfinite(delta_J) and np.isfinite(mvir):\n",
    "                    eta_list.append(eta)\n",
    "                    delta_J_list.append(delta_J)\n",
    "                    mass_list.append(mvir)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] failed to process {suite} halo {fname}: {e}\")\n",
    "\n",
    "    # convert to arrays\n",
    "    delta_J_arr = np.array(delta_J_list)\n",
    "    eta_arr     = np.array(eta_list)\n",
    "    logM_arr    = np.log10(np.array(mass_list))\n",
    "\n",
    "    # check we have enough halos\n",
    "    if delta_J_arr.size < 5:\n",
    "        print(\"[Warning] Too few halos for meaningful correlation.\")\n",
    "        return\n",
    "\n",
    "    # 2) normalize δJ by median and std\n",
    "    med_J = np.median(delta_J_arr)\n",
    "    std_J = np.std(delta_J_arr)\n",
    "    if std_J <= 0:\n",
    "        print(\"[Warning] zero variance in Jeans deviation; cannot normalize.\")\n",
    "        return\n",
    "    delta_J_norm = (delta_J_arr - med_J) / std_J\n",
    "\n",
    "    # 3) compute Spearman correlation\n",
    "    rho_s, p_s = spearmanr(delta_J_norm, eta_arr)\n",
    "\n",
    "    # 4) plotting\n",
    "    plt.figure(figsize=(7,6), dpi=500)\n",
    "    sc = plt.scatter(\n",
    "        delta_J_norm, eta_arr,\n",
    "        c=logM_arr, cmap=\"viridis\", s=25, alpha=0.8, edgecolors=\"none\"\n",
    "    )\n",
    "    plt.axhline(1.0, color=\"gray\", linestyle=\"--\", label=\"Virial equilibrium (η=1)\")\n",
    "    cbar = plt.colorbar(sc)\n",
    "    cbar.set_label(r\"$\\log_{10}(M_{\\rm vir}/M_\\odot)$\", fontsize=10)\n",
    "\n",
    "    plt.xlabel(r\"$\\Delta \\delta_J / \\sigma_{\\delta_J}$\")\n",
    "    plt.ylabel(r\"$\\eta = 2K/|U|$\", fontsize=11)\n",
    "    plt.grid(True, linestyle=\":\")\n",
    "    plt.legend(loc=\"upper right\", fontsize=10)\n",
    "\n",
    "    txt = f\"$\\\\rho$ = {rho_s:.3f}\\n$p$ = {p_s:.2e}\"\n",
    "    plt.text(0.95, 0.05, txt,\n",
    "             transform=plt.gca().transAxes,\n",
    "             ha='right', va='bottom',\n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.8),\n",
    "             fontsize=10)\n",
    "    plt.savefig(os.path.join(out_dir, f\"delta_jeans_vs_eta.pdf\"))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "compare_normalized_jeans_deviation_vs_virial_ratio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede3c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def const_model(r, a):\n",
    "    \"\"\"A one-parameter constant model: y(r) = a.\"\"\"\n",
    "    return a * np.ones_like(r)\n",
    "\n",
    "def plot_bestfit_ppsd_slope_vs_jeans_deviation_norm(r_fit_range= (0.01, 1.0)): \n",
    "    slope_vals, jeans_norm_vals, log_mass_vals = [], [], []\n",
    "\n",
    "    for suite in suite_names:\n",
    "        slope_dir  = os.path.join(base_dir, \"output\", suite, \"ppsd_slope_profiles_r\")\n",
    "        jeans_path = os.path.join(base_dir, \"output\", suite, \"jeans_deviation_total.csv\")\n",
    "        mass_path  = os.path.join(base_dir, \"output\", suite, \"halo_mass.csv\")\n",
    "\n",
    "        df_jeans = pd.read_csv(jeans_path)\n",
    "        dJ       = pd.to_numeric(df_jeans[\"delta_J_tot\"], errors=\"coerce\")\n",
    "        median_j, std_j = np.nanmedian(dJ), np.nanstd(dJ)\n",
    "        jeans_norm = {hid: (dj - median_j) / std_j for hid, dj in zip(df_jeans[\"halo_id\"], dJ)}\n",
    "\n",
    "        df_mass  = pd.read_csv(mass_path)\n",
    "        mass_map = dict(zip(df_mass[\"halo_id\"], pd.to_numeric(df_mass[\"mvir\"], errors=\"coerce\")))\n",
    "\n",
    "        for fname in sorted(f for f in os.listdir(slope_dir) if f.endswith(\".csv\")):\n",
    "            try:\n",
    "                hid = int(fname.split(\"_\")[1]) \n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                df = pd.read_csv(os.path.join(slope_dir, fname))\n",
    "                r  = pd.to_numeric(df[\"r_scaled\"], errors=\"coerce\").to_numpy(float)\n",
    "                s  = pd.to_numeric(df[\"slope_Q_r\"], errors=\"coerce\").to_numpy(float)\n",
    "\n",
    "                mask = (r >= r_fit_range[0]) & (r <= r_fit_range[1]) & np.isfinite(s)\n",
    "                if mask.sum() < 5:\n",
    "                    continue  # not enough points for a stable fit\n",
    "\n",
    "                r_fit, s_fit = r[mask], s[mask]\n",
    "\n",
    "                try:\n",
    "                    popt, _ = curve_fit(const_model, r_fit, s_fit, p0=[np.median(s_fit)])\n",
    "                    best_slope = popt[0]\n",
    "                except Exception:\n",
    "                    best_slope = np.median(s_fit)\n",
    "\n",
    "                dj_norm = jeans_norm.get(hid, np.nan)\n",
    "                mvir    = mass_map.get(hid,  np.nan)\n",
    "\n",
    "                if np.isfinite(best_slope) and np.isfinite(dj_norm):\n",
    "                    slope_vals.append(best_slope)\n",
    "                    jeans_norm_vals.append(dj_norm)\n",
    "                    log_mass_vals.append(np.log10(mvir) if np.isfinite(mvir) else np.nan)\n",
    "\n",
    "            except Exception as err:\n",
    "                print(f\"[Warning] {suite}/{fname}: {err}\")\n",
    "\n",
    "    slope_vals, jeans_norm_vals, log_mass_vals = map(np.asarray, (slope_vals, jeans_norm_vals, log_mass_vals))\n",
    "\n",
    "    rho, pval = spearmanr(jeans_norm_vals, slope_vals)\n",
    "\n",
    "    plt.figure(figsize=(7, 6), dpi=500)\n",
    "    sc = plt.scatter(jeans_norm_vals, slope_vals, c=log_mass_vals,\n",
    "                     cmap=\"viridis\", s=20, alpha=0.8)\n",
    "    plt.colorbar(sc, label=r\"$\\log_{10}(M_{\\rm vir}/M_\\odot)$\")\n",
    "    plt.xlabel(r\"$\\Delta \\delta_J / \\sigma_{\\delta_J}$\")\n",
    "    plt.ylabel(r\"$\\langle d\\log Q_r / d\\log r\\rangle$\")\n",
    "    txt = f\"$\\\\rho$ = {rho:.3f}\\n$p$ = {pval:.2e}\"\n",
    "    plt.gca().text(0.85, 0.9, txt, transform=plt.gca().transAxes,\n",
    "                   ha=\"center\", va=\"bottom\",\n",
    "                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "    plt.grid(True, linestyle=\":\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, f\"ppsd_slope_vs_delta_jeans.pdf\"))\n",
    "    plt.show()\n",
    "\n",
    "suite_names = [\"SymphonyLMC\", \"SymphonyMilkyWay\", \"SymphonyGroup\", \"SymphonyLCluster\"]\n",
    "plot_bestfit_ppsd_slope_vs_jeans_deviation_norm(r_fit_range=(5e-3, 1.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1181f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantify_jeans_vs_cgamma(x_var=\"cvir\"):\n",
    "    x_vals, delta_j_vals, mass_vals = [], [], []\n",
    "\n",
    "    for suite in suite_names:\n",
    "        cvir_path = os.path.join(base_dir, \"output\", suite, \"halo_concentrations.csv\")\n",
    "        gamma_path = os.path.join(base_dir, \"output\", suite, \"accretion_rates.csv\")\n",
    "        mass_path = os.path.join(base_dir, \"output\", suite, \"halo_mass.csv\")\n",
    "        jeans_path = os.path.join(base_dir, \"output\", suite, \"jeans_deviation_total.csv\")\n",
    "\n",
    "        df_cvir = pd.read_csv(cvir_path)\n",
    "        df_gamma = pd.read_csv(gamma_path)\n",
    "        df_mass = pd.read_csv(mass_path)\n",
    "        df_jeans = pd.read_csv(jeans_path)\n",
    "\n",
    "        # Create lookup dictionaries\n",
    "        cvir_dict = dict(zip(df_cvir[\"halo_id\"], pd.to_numeric(df_cvir[\"cvir\"], errors='coerce')))\n",
    "        gamma_dict = dict(zip(df_gamma[\"halo_index\"], pd.to_numeric(df_gamma[\"gamma\"], errors='coerce')))\n",
    "        mass_dict = dict(zip(df_mass[\"halo_id\"], pd.to_numeric(df_mass[\"mvir\"], errors='coerce')))\n",
    "        delta_j_dict = dict(zip(df_jeans[\"halo_id\"], pd.to_numeric(df_jeans[\"delta_J_tot\"], errors='coerce')))\n",
    "\n",
    "        # Normalized variables (computed within each suite)\n",
    "        if x_var == \"delta_c_norm\":\n",
    "            c_vals = df_cvir[\"cvir\"].values\n",
    "            c_med, c_std = np.nanmedian(c_vals), np.nanstd(c_vals)\n",
    "            x_dict = {row[\"halo_id\"]: (row[\"cvir\"] - c_med) / c_std for _, row in df_cvir.iterrows()}\n",
    "\n",
    "        elif x_var == \"delta_gamma_norm\":\n",
    "            vals = df_gamma[\"gamma\"].values\n",
    "            valid_mask = (vals > 0) & np.isfinite(vals)\n",
    "            log_vals = np.log10(vals[valid_mask])\n",
    "            g_med, g_std = np.nanmedian(log_vals), np.nanstd(log_vals)\n",
    "            x_dict = {\n",
    "                row[\"halo_index\"]: (np.log10(row[\"gamma\"]) - g_med) / g_std\n",
    "                for _, row in df_gamma.iterrows()\n",
    "                if row[\"gamma\"] > 0 and np.isfinite(row[\"gamma\"])\n",
    "            }\n",
    "\n",
    "        # Loop over halos\n",
    "        for halo_id in delta_j_dict:\n",
    "            delta_j = delta_j_dict.get(halo_id)\n",
    "            mass = mass_dict.get(halo_id, np.nan)\n",
    "\n",
    "            if x_var == \"cvir\":\n",
    "                x = cvir_dict.get(halo_id)\n",
    "            elif x_var == \"gamma\":\n",
    "                x = gamma_dict.get(halo_id)\n",
    "                x = np.log10(x) if x is not None and x > 0 else np.nan\n",
    "            elif x_var in [\"delta_c_norm\", \"delta_gamma_norm\"]:\n",
    "                x = x_dict.get(halo_id)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            x = pd.to_numeric(x, errors='coerce')\n",
    "            delta_j = pd.to_numeric(delta_j, errors='coerce')\n",
    "            if np.isfinite(x) and np.isfinite(delta_j):\n",
    "                x_vals.append(x)\n",
    "                delta_j_vals.append(delta_j)\n",
    "                mass_vals.append(mass)\n",
    "\n",
    "    x_vals = np.array(x_vals)\n",
    "    delta_j_vals = np.array(delta_j_vals)\n",
    "    mass_vals = np.array(mass_vals)\n",
    "\n",
    "    if len(x_vals) < 2:\n",
    "        print(\"[Warning] Not enough valid data.\")\n",
    "        return\n",
    "\n",
    "    log_mass = np.log10(mass_vals)\n",
    "    spearman_r, spearman_p = spearmanr(x_vals, delta_j_vals)\n",
    "\n",
    "    plt.figure(figsize=(7, 6), dpi=600)\n",
    "    scatter = plt.scatter(x_vals, delta_j_vals, c=log_mass, cmap=\"viridis\", s=20, alpha=0.8)\n",
    "    plt.colorbar(scatter, label=r\"$\\log_{10}(M_{\\rm vir})$\")\n",
    "    plt.grid(True, linestyle=\":\")\n",
    "    plt.xlabel({\n",
    "        \"cvir\": r\"$c$\",\n",
    "        \"gamma\": r\"$\\log_{10}(\\Gamma)$\",\n",
    "        \"delta_c_norm\": r\"$\\Delta c/\\sigma_c$\",\n",
    "        \"delta_gamma_norm\": r\"$\\Delta \\log \\Gamma/\\sigma_{\\log \\Gamma}$\"\n",
    "    }.get(x_var, x_var))\n",
    "    plt.ylabel(r\"$\\delta_J$\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    textstr = '\\n'.join((\n",
    "        rf\"$\\rho$ = {spearman_r:.3f}\",\n",
    "        rf\"$p$ = {spearman_p:.2e}\"\n",
    "    ))\n",
    "    plt.text(0.85, 0.9, textstr,\n",
    "             transform=plt.gca().transAxes,\n",
    "             fontsize=10, va='bottom', ha='center',\n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", edgecolor=\"gray\", alpha=0.8))\n",
    "    plt.savefig(os.path.join(out_dir, f\"delta_jeans_vs_{x_var}.pdf\"))\n",
    "    plt.show()\n",
    "\n",
    "quantify_jeans_vs_cgamma(x_var=\"delta_c_norm\")\n",
    "quantify_jeans_vs_cgamma(x_var=\"delta_gamma_norm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Astronomy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
