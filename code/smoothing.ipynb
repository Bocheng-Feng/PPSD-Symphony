{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a98b15b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynumdiff\n",
    "import pynumdiff.optimize\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7157ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppsd_profiles(base_dir, suite_name):\n",
    "    # Define input/output directories\n",
    "    density_dir = os.path.join(base_dir, \"output\", suite_name, \"density_profiles\")\n",
    "    mass_dir = os.path.join(base_dir, \"output\", suite_name, \"mass_profiles\")\n",
    "    velocity_dir = os.path.join(base_dir, \"output\", suite_name, \"velocity_profiles\")\n",
    "    output_dir = os.path.join(base_dir, \"output\", suite_name, \"ppsd_profiles\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Collect file names\n",
    "    density_files = sorted([f for f in os.listdir(density_dir) if f.endswith(\".csv\")])\n",
    "    mass_files = sorted([f for f in os.listdir(mass_dir) if f.endswith(\".csv\")])\n",
    "    velocity_files = sorted([f for f in os.listdir(velocity_dir) if f.endswith(\".csv\")])\n",
    "\n",
    "    # Loop through halos and compute Q_r and Q_tot\n",
    "    for halo_idx, (f_rho, f_mass, f_vel) in enumerate(zip(density_files, mass_files, velocity_files)):\n",
    "        df_rho = pd.read_csv(os.path.join(density_dir, f_rho))\n",
    "        df_mass = pd.read_csv(os.path.join(mass_dir, f_mass))\n",
    "        df_vel = pd.read_csv(os.path.join(velocity_dir, f_vel))\n",
    "\n",
    "        # Load profile data\n",
    "        r = df_rho[\"r_scaled\"].values\n",
    "        rho = df_rho[\"rho_scaled\"].values\n",
    "        m = df_mass[\"m_scaled\"].values\n",
    "        sigma_rad = df_vel[\"sigma_rad_scaled\"].values\n",
    "        sigma_tot = df_vel[\"sigma_total_scaled\"].values\n",
    "\n",
    "        # Compute pseudo phase-space densities\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            Q_r = np.where(sigma_rad > 0, rho / sigma_rad**3, np.nan)\n",
    "            Q_tot = np.where(sigma_tot > 0, rho / sigma_tot**3, np.nan)\n",
    "\n",
    "        # Save to CSV\n",
    "        df_out = pd.DataFrame({\n",
    "            \"r_scaled\": r,\n",
    "            \"m_scaled\": m,\n",
    "            \"Q_r\": Q_r,\n",
    "            \"Q_tot\": Q_tot\n",
    "        })\n",
    "        df_out.to_csv(f\"{base_dir}/output/{suite_name}/ppsd_profiles/halo_{halo_idx:03d}_profile.csv\", index=False)\n",
    "\n",
    "    print(f\"[Saved] PPSD profiles for {suite_name} saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b40355e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved] PPSD profiles for SymphonyLMC saved to /Users/fengbocheng/Projects/Symphony-PPSD/output/SymphonyLMC/ppsd_profiles\n",
      "[Saved] PPSD profiles for SymphonyMilkyWay saved to /Users/fengbocheng/Projects/Symphony-PPSD/output/SymphonyMilkyWay/ppsd_profiles\n",
      "[Saved] PPSD profiles for SymphonyGroup saved to /Users/fengbocheng/Projects/Symphony-PPSD/output/SymphonyGroup/ppsd_profiles\n",
      "[Saved] PPSD profiles for SymphonyLCluster saved to /Users/fengbocheng/Projects/Symphony-PPSD/output/SymphonyLCluster/ppsd_profiles\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/Users/fengbocheng/Projects/Symphony-PPSD\"\n",
    "suite_names = [\n",
    "    \"SymphonyLMC\",\n",
    "    \"SymphonyMilkyWay\",\n",
    "    \"SymphonyGroup\",\n",
    "    \"SymphonyLCluster\",\n",
    "]\n",
    "\n",
    "for suite in suite_names:\n",
    "    ppsd_profiles(base_dir, suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bba52e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this is the version that smoothing the derivative of density and velocity sperately and then combine them to get the smoothing derivative of ppsd\n",
    "def get_diff_and_optimize_funcs(method):\n",
    "    submodules = [\n",
    "        'kalman_smooth',\n",
    "        'smooth_finite_difference',\n",
    "        'finite_difference',\n",
    "        'total_variation_regularization',\n",
    "        'linear_model'\n",
    "    ]\n",
    "    for submod in submodules:\n",
    "        try:\n",
    "            mod_optimize = getattr(pynumdiff.optimize, submod)\n",
    "            mod_diff = getattr(pynumdiff, submod)\n",
    "            if hasattr(mod_optimize, method) and hasattr(mod_diff, method):\n",
    "                return getattr(mod_diff, method), getattr(mod_optimize, method)\n",
    "        except AttributeError:\n",
    "            continue\n",
    "    raise ValueError(f\"Method '{method}' not found in any submodule.\")\n",
    "\n",
    "def fit_and_save_ppsd_slopes(base_dir, suite_name, method='constant_jerk', tvgamma=None):\n",
    "    density_dir = os.path.join(base_dir, \"output\", suite_name, \"density_profiles\")\n",
    "    velocity_dir = os.path.join(base_dir, \"output\", suite_name, \"velocity_profiles\")\n",
    "    mass_dir = os.path.join(base_dir, \"output\", suite_name, \"mass_profiles\")\n",
    "    slope_r_dir = os.path.join(base_dir, \"output\", suite_name, \"ppsd_slope_profiles_r\")\n",
    "    slope_m_dir = os.path.join(base_dir, \"output\", suite_name, \"ppsd_slope_profiles_m\")\n",
    "    os.makedirs(slope_r_dir, exist_ok=True)\n",
    "    os.makedirs(slope_m_dir, exist_ok=True)\n",
    "\n",
    "    density_files = sorted([f for f in os.listdir(density_dir) if f.endswith(\".csv\")])\n",
    "    velocity_files = sorted([f for f in os.listdir(velocity_dir) if f.endswith(\".csv\")])\n",
    "    mass_files = sorted([f for f in os.listdir(mass_dir) if f.endswith(\".csv\")])\n",
    "    n_halos = len(density_files)\n",
    "\n",
    "    def fit_derivative(y, dt):\n",
    "        try:\n",
    "            diff_func, optimize_func = get_diff_and_optimize_funcs(method)\n",
    "            kwargs = {'tvgamma': tvgamma} if 'tvgamma' in optimize_func.__code__.co_varnames else {}\n",
    "            params, _ = optimize_func(y, dt, **kwargs)\n",
    "            _, dydx = diff_func(y, dt, params)\n",
    "            return dydx\n",
    "        except Exception as e:\n",
    "            print(f\"{method} derivative fit failed: {e}\")\n",
    "            return None\n",
    "\n",
    "    for halo_idx in range(n_halos):\n",
    "        try:\n",
    "            df_rho = pd.read_csv(os.path.join(density_dir, density_files[i]))\n",
    "            df_vel = pd.read_csv(os.path.join(velocity_dir, velocity_files[i]))\n",
    "            df_mass = pd.read_csv(os.path.join(mass_dir, mass_files[i]))\n",
    "        except Exception as e:\n",
    "            print(f\"[Halo {i}] loading profiles failed: {e}\")\n",
    "            continue\n",
    "\n",
    "        r = df_rho[\"r_scaled\"].values\n",
    "        m = df_mass[\"m_scaled\"].values\n",
    "        rho = df_rho[\"rho_scaled\"].values\n",
    "        sigma_tot = df_vel[\"sigma_total_scaled\"].values\n",
    "        sigma_rad = df_vel[\"sigma_rad_scaled\"].values\n",
    "\n",
    "        dt_r = np.diff(np.log10(r)).mean()\n",
    "        dt_m = np.diff(np.log10(m)).mean()\n",
    "\n",
    "        log_rho = np.log10(rho)\n",
    "        log_sigma_tot = np.log10(sigma_tot)\n",
    "        log_sigma_rad = np.log10(sigma_rad)\n",
    "\n",
    "        drho_dlogr = fit_derivative(log_rho, dt_r)\n",
    "        dsigma_tot_dlogr = fit_derivative(log_sigma_tot, dt_r)\n",
    "        dsigma_rad_dlogr = fit_derivative(log_sigma_rad, dt_r)\n",
    "\n",
    "        drho_dlogm = fit_derivative(log_rho, dt_m)\n",
    "        dsigma_tot_dlogm = fit_derivative(log_sigma_tot, dt_m)\n",
    "        dsigma_rad_dlogm = fit_derivative(log_sigma_rad, dt_m)\n",
    "\n",
    "        if any(x is None for x in [drho_dlogr, dsigma_tot_dlogr, dsigma_rad_dlogr,\n",
    "                                drho_dlogm, dsigma_tot_dlogm, dsigma_rad_dlogm]):\n",
    "            print(f\"[Halo {i}] derivative fitting failed, skipping\")\n",
    "            continue\n",
    "\n",
    "        slope_Q_tot_r = drho_dlogr - 3 * dsigma_tot_dlogr\n",
    "        slope_Q_rad_r = drho_dlogr - 3 * dsigma_rad_dlogr\n",
    "        slope_Q_tot_m = drho_dlogm - 3 * dsigma_tot_dlogm\n",
    "        slope_Q_rad_m = drho_dlogm - 3 * dsigma_rad_dlogm\n",
    "\n",
    "        df_r = pd.DataFrame({\"r_scaled\": r, \"slope_Q_r\": slope_Q_rad_r, \"slope_Q_tot\": slope_Q_tot_r})\n",
    "        df_m = pd.DataFrame({\"m_scaled\": m, \"slope_Q_r\": slope_Q_rad_m, \"slope_Q_tot\": slope_Q_tot_m})\n",
    "\n",
    "        df_r.to_csv(os.path.join(slope_r_dir, f\"slope_profile_r_{halo_idx:03d}.csv\"), index=False)\n",
    "        df_m.to_csv(os.path.join(slope_m_dir, f\"slope_profile_m_{halo_idx:03d}.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793b18a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this is the version that smooth the derivative of derivative of ppsd derictly\n",
    "def get_diff_and_optimize_funcs(method):\n",
    "    submodules = [\n",
    "        'kalman_smooth',\n",
    "        'smooth_finite_difference',\n",
    "        'finite_difference',\n",
    "        'total_variation_regularization',\n",
    "        'linear_model'\n",
    "    ]\n",
    "    for submod in submodules:\n",
    "        try:\n",
    "            mod_optimize = getattr(pynumdiff.optimize, submod)\n",
    "            mod_diff = getattr(pynumdiff, submod)\n",
    "            if hasattr(mod_optimize, method) and hasattr(mod_diff, method):\n",
    "                return getattr(mod_diff, method), getattr(mod_optimize, method)\n",
    "        except AttributeError:\n",
    "            continue\n",
    "    raise ValueError(f\"Method '{method}' not found in any submodule.\")\n",
    "\n",
    "def fit_and_save_ppsd_slopes(base_dir, suite_name, method='constant_jerk', tvgamma=None):\n",
    "    ppsd_dir = os.path.join(base_dir, \"output\", suite_name, \"ppsd_profiles\")\n",
    "    slope_r_dir = os.path.join(base_dir, \"output\", suite_name, \"ppsd_slope_profiles_r\")\n",
    "    slope_m_dir = os.path.join(base_dir, \"output\", suite_name, \"ppsd_slope_profiles_m\")\n",
    "    os.makedirs(slope_r_dir, exist_ok=True)\n",
    "    os.makedirs(slope_m_dir, exist_ok=True)\n",
    "\n",
    "    ppsd_files = sorted([f for f in os.listdir(ppsd_dir) if f.endswith(\".csv\")])\n",
    "    n_halos = len(ppsd_files)\n",
    "\n",
    "    def fit_derivative(y, dt):\n",
    "        try:\n",
    "            diff_func, optimize_func = get_diff_and_optimize_funcs(method)\n",
    "            kwargs = {'tvgamma': tvgamma} if 'tvgamma' in optimize_func.__code__.co_varnames else {}\n",
    "            params, _ = optimize_func(y, dt, **kwargs)\n",
    "            _, dydx = diff_func(y, dt, params)\n",
    "            return dydx\n",
    "        except Exception as e:\n",
    "            print(f\"{method} derivative fit failed: {e}\")\n",
    "            return None\n",
    "\n",
    "    for halo_idx in range(n_halos):\n",
    "        try:\n",
    "            df_Q = pd.read_csv(os.path.join(ppsd_dir, ppsd_files[halo_idx]))\n",
    "        except Exception as e:\n",
    "            print(f\"[Halo {i}] loading profiles failed: {e}\")\n",
    "            continue\n",
    "\n",
    "        r = df_Q[\"r_scaled\"].values\n",
    "        m = df_Q[\"m_scaled\"].values\n",
    "        Q_tot = df_Q[\"Q_tot\"].values\n",
    "        Q_r = df_Q[\"Q_r\"].values\n",
    "\n",
    "        dt_r = np.diff(np.log10(r)).mean()\n",
    "        dt_m = np.diff(np.log10(m)).mean()\n",
    "\n",
    "        log_Q_r = np.log10(Q_r)\n",
    "        log_Q_tot = np.log10(Q_tot)\n",
    "\n",
    "        slope_Q_tot_r = fit_derivative(log_Q_tot, dt_r)\n",
    "        slope_Q_rad_r = fit_derivative(log_Q_r, dt_r)\n",
    "        slope_Q_tot_m = fit_derivative(log_Q_tot, dt_m)\n",
    "        slope_Q_rad_m = fit_derivative(log_Q_r, dt_m)\n",
    "\n",
    "        df_r = pd.DataFrame({\"r_scaled\": r, \"slope_Q_r\": slope_Q_rad_r, \"slope_Q_tot\": slope_Q_tot_r})\n",
    "        df_m = pd.DataFrame({\"m_scaled\": m, \"slope_Q_r\": slope_Q_rad_m, \"slope_Q_tot\": slope_Q_tot_m})\n",
    "\n",
    "        df_r.to_csv(os.path.join(slope_r_dir, f\"halo_{halo_idx:03d}_profile.csv\"), index=False)\n",
    "        df_m.to_csv(os.path.join(slope_m_dir, f\"halo_{halo_idx:03d}_profile.csv\"), index=False)\n",
    "\n",
    "for suite in suite_names:\n",
    "    fit_and_save_ppsd_slopes(base_dir, suite, method='constant_jerk', tvgamma=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Astronomy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
