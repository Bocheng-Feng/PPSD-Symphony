{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0acdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy.constants import G\n",
    "from astropy import units as u\n",
    "from scipy.integrate import quad\n",
    "import symlib\n",
    "import os\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.optimize import curve_fit   \n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "base_dir = \"/Users/fengbocheng/Projects/Symphony-PPSD\"\n",
    "suite_names = [\"SymphonyLMC\", \"SymphonyMilkyWay\", \"SymphonyGroup\", \"SymphonyLCluster\", \"SymphonyCluster\"]\n",
    "sim_colors = {\n",
    "        \"SymphonyLMC\": sns.color_palette(\"colorblind\")[4],\n",
    "        \"SymphonyMilkyWay\": sns.color_palette(\"colorblind\")[0],\n",
    "        \"SymphonyGroup\": sns.color_palette(\"colorblind\")[2],\n",
    "        \"SymphonyLCluster\": sns.color_palette(\"colorblind\")[1],\n",
    "        \"SymphonyCluster\": sns.color_palette(\"colorblind\")[3],\n",
    "    }\n",
    "sim_names = {\n",
    "        \"SymphonyLMC\": \"LMC\",\n",
    "        \"SymphonyMilkyWay\": \"Milky~Way\",\n",
    "        \"SymphonyGroup\": \"Group\",\n",
    "        \"SymphonyLCluster\": \"L-Cluster\",\n",
    "        \"SymphonyCluster\": \"Cluster\",\n",
    "    }\n",
    "mean_cvir = {\n",
    "    \"SymphonyLMC\": 12.2,\n",
    "    \"SymphonyMilkyWay\": 10.8,\n",
    "    \"SymphonyGroup\": 9.0,\n",
    "    \"SymphonyLCluster\": 5.0,\n",
    "    \"SymphonyCluster\": 5.6,\n",
    "}\n",
    "out_dir = os.path.join(base_dir, \"output\", \"FIGURE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7573627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "def chi_squared_between_suites(\n",
    "    base_dir,\n",
    "    suite_names,\n",
    "    quantity=\"Q_r\",       # Options: \"Q_r\", \"Q_tot\", \"slope_Q_r\", \"slope_Q_tot\"\n",
    "    coord=\"r\",            # \"r\" = radius; \"m\" = enclosed mass\n",
    "    x_range=None,         # Tuple (xmin, xmax) to limit the x-range for comparison\n",
    "    n_points=100,         # Number of interpolation points on common grid\n",
    "    plot=True,            # If True, show comparison plots\n",
    "):\n",
    "    x_key = \"r_scaled\" if coord == \"r\" else \"m_scaled\"\n",
    "    is_slope = quantity.startswith(\"slope_\")\n",
    "    suite_data = {}\n",
    "    global_x_min = np.inf\n",
    "    global_x_max = -np.inf\n",
    "\n",
    "    for suite in suite_names:\n",
    "        x_stack, y_stack = [], []\n",
    "\n",
    "        if is_slope:\n",
    "            slope_dir = os.path.join(base_dir, \"output\", suite, f\"ppsd_slope_profiles_{coord}\")\n",
    "            files = sorted(f for f in os.listdir(slope_dir) if f.endswith(\".csv\") and f.startswith(\"halo_\"))\n",
    "\n",
    "            for f in files:\n",
    "                try:\n",
    "                    df = pd.read_csv(os.path.join(slope_dir, f))\n",
    "                    if x_key not in df.columns or quantity not in df.columns:\n",
    "                        continue\n",
    "                    x = df[x_key].values\n",
    "                    y = df[quantity].values\n",
    "                    x_stack.append(x)\n",
    "                    y_stack.append(y)\n",
    "\n",
    "                    valid_x = x[np.isfinite(x)]\n",
    "                    if valid_x.size > 0:\n",
    "                        global_x_min = min(global_x_min, valid_x.min())\n",
    "                        global_x_max = max(global_x_max, valid_x.max())\n",
    "                except Exception as e:\n",
    "                    print(f\"[Warning] Failed to read slope {f}: {e}\")\n",
    "                    continue\n",
    "        else:\n",
    "            profile_dir = os.path.join(base_dir, \"output\", suite, \"ppsd_profiles\")\n",
    "            files = sorted(f for f in os.listdir(profile_dir) if f.endswith(\".csv\"))\n",
    "\n",
    "            for f in files:\n",
    "                df = pd.read_csv(os.path.join(profile_dir, f))\n",
    "                if x_key not in df.columns or quantity not in df.columns:\n",
    "                    continue\n",
    "                x = df[x_key].values\n",
    "                y = df[quantity].values\n",
    "                x_stack.append(x)\n",
    "                y_stack.append(y)\n",
    "\n",
    "                valid_x = x[np.isfinite(x)]\n",
    "                if valid_x.size > 0:\n",
    "                    global_x_min = min(global_x_min, valid_x.min())\n",
    "                    global_x_max = max(global_x_max, valid_x.max())\n",
    "\n",
    "        if len(x_stack) == 0:\n",
    "            raise RuntimeError(f\"No valid profiles found for suite {suite}\")\n",
    "\n",
    "        suite_data[suite] = {\"x_stack\": x_stack, \"y_stack\": y_stack}\n",
    "\n",
    "    # Step 2: Interpolation grid\n",
    "    xmin, xmax = x_range\n",
    "    \n",
    "    x_common = np.logspace(np.log10(xmin), np.log10(xmax), n_points)\n",
    "    # Step 3: Interpolate and average\n",
    "    for suite in suite_names:\n",
    "        y_interp_all = []\n",
    "        for x_arr, y_arr in zip(suite_data[suite][\"x_stack\"], suite_data[suite][\"y_stack\"]):\n",
    "            y_interp = np.interp(x_common, x_arr, y_arr, left=np.nan, right=np.nan)\n",
    "            y_interp_all.append(y_interp)\n",
    "        y_interp_all = np.array(y_interp_all)\n",
    "\n",
    "        suite_data[suite][\"x\"] = x_common\n",
    "        suite_data[suite][\"mean\"] = np.nanmean(y_interp_all, axis=0)\n",
    "        suite_data[suite][\"std\"] = np.nanstd(y_interp_all, axis=0)\n",
    "\n",
    "    # Step 4: χ² test\n",
    "    results = {}\n",
    "    for s1, s2 in itertools.combinations(suite_names, 2):\n",
    "        d1, d2 = suite_data[s1], suite_data[s2]\n",
    "        x = d1[\"x\"]\n",
    "        μ1, σ1 = d1[\"mean\"], d1[\"std\"]\n",
    "        μ2, σ2 = d2[\"mean\"], d2[\"std\"]\n",
    "\n",
    "        valid = np.isfinite(μ1) & np.isfinite(μ2) & (σ1 + σ2 > 0)\n",
    "        if x_range is not None:\n",
    "            valid &= (x >= xmin) & (x <= xmax)\n",
    "\n",
    "        ν = np.sum(valid)\n",
    "        if ν < 5:\n",
    "            print(f\"[Warning] Too few valid points for {s1} vs {s2}\")\n",
    "            continue\n",
    "\n",
    "        χ2_val = np.sum((μ1[valid] - μ2[valid])**2 / (σ1[valid]**2 + σ2[valid]**2))\n",
    "        p_val = 1 - chi2.cdf(χ2_val, ν)\n",
    "\n",
    "        results[(s1, s2)] = {\"chi2\": χ2_val, \"dof\": ν, \"pval\": p_val}\n",
    "\n",
    "        if plot:\n",
    "            plt.figure(figsize=(6, 4), dpi=400)\n",
    "            plt.errorbar(x[valid], μ1[valid], yerr=σ1[valid], fmt=\"-o\", label=s1, markersize=3, capsize=2)\n",
    "            plt.errorbar(x[valid], μ2[valid], yerr=σ2[valid], fmt=\"-s\", label=s2, markersize=3, capsize=2)\n",
    "            plt.xscale(\"log\")\n",
    "            plt.xlabel(f\"{coord.upper()} (scaled)\")\n",
    "            plt.ylabel(quantity)\n",
    "            plt.title(f\"{s1} vs {s2}  |  χ²={χ2_val:.1f}, ν={ν}, p={p_val:.3g}\")\n",
    "            plt.grid(True, which=\"both\", ls=\":\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "60142dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_test_profilewise_between_suites_with_significance(\n",
    "    base_dir,\n",
    "    suite_names,\n",
    "    quantity=\"Q_r\",\n",
    "    coord=\"r\",\n",
    "    x_range=None,\n",
    "    n_points=100,\n",
    "    plot=True,\n",
    "    significance_levels=[0.05, 0.01]  # Mark thresholds for statistical significance\n",
    "):\n",
    "    x_key = \"r_scaled\" if coord == \"r\" else \"m_scaled\"\n",
    "    is_slope = quantity.startswith(\"slope_\")\n",
    "    suite_data = {}\n",
    "    global_x_min = np.inf\n",
    "    global_x_max = -np.inf\n",
    "\n",
    "    for suite in suite_names:\n",
    "        x_stack, y_stack = [], []\n",
    "\n",
    "        if is_slope:\n",
    "            slope_dir = os.path.join(base_dir, \"output\", suite, f\"ppsd_slope_profiles_{coord}\")\n",
    "            files = sorted(f for f in os.listdir(slope_dir) if f.endswith(\".csv\") and f.startswith(\"halo_\"))\n",
    "        else:\n",
    "            profile_dir = os.path.join(base_dir, \"output\", suite, \"ppsd_profiles\")\n",
    "            files = sorted(f for f in os.listdir(profile_dir) if f.endswith(\".csv\"))\n",
    "\n",
    "        for f in files:\n",
    "            try:\n",
    "                path = os.path.join(slope_dir if is_slope else profile_dir, f)\n",
    "                df = pd.read_csv(path)\n",
    "                if x_key not in df.columns or quantity not in df.columns:\n",
    "                    continue\n",
    "                x = df[x_key].values\n",
    "                y = df[quantity].values\n",
    "                x_stack.append(x)\n",
    "                y_stack.append(y)\n",
    "                valid_x = x[np.isfinite(x)]\n",
    "                if valid_x.size > 0:\n",
    "                    global_x_min = min(global_x_min, valid_x.min())\n",
    "                    global_x_max = max(global_x_max, valid_x.max())\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Failed to read {f}: {e}\")\n",
    "                continue\n",
    "\n",
    "        if len(x_stack) == 0:\n",
    "            raise RuntimeError(f\"No valid profiles found for suite {suite}\")\n",
    "\n",
    "        suite_data[suite] = {\"x_stack\": x_stack, \"y_stack\": y_stack}\n",
    "\n",
    "    if x_range is None:\n",
    "        xmin, xmax = global_x_min, global_x_max\n",
    "    else:\n",
    "        xmin, xmax = x_range\n",
    "\n",
    "    x_common = np.logspace(np.log10(xmin), np.log10(xmax), n_points)\n",
    "\n",
    "    for suite in suite_names:\n",
    "        y_interp_all = []\n",
    "        for x_arr, y_arr in zip(suite_data[suite][\"x_stack\"], suite_data[suite][\"y_stack\"]):\n",
    "            y_interp = np.interp(x_common, x_arr, y_arr, left=np.nan, right=np.nan)\n",
    "            y_interp_all.append(y_interp)\n",
    "        suite_data[suite][\"y_interp_all\"] = np.array(y_interp_all)\n",
    "\n",
    "    results = {}\n",
    "    for s1, s2 in itertools.combinations(suite_names, 2):\n",
    "        y1_all = suite_data[s1][\"y_interp_all\"]\n",
    "        y2_all = suite_data[s2][\"y_interp_all\"]\n",
    "\n",
    "        ks_stats = []\n",
    "        p_values = []\n",
    "        for i in range(n_points):\n",
    "            v1 = y1_all[:, i]\n",
    "            v2 = y2_all[:, i]\n",
    "            v1 = v1[np.isfinite(v1)]\n",
    "            v2 = v2[np.isfinite(v2)]\n",
    "\n",
    "            if len(v1) < 5 or len(v2) < 5:\n",
    "                ks_stats.append(np.nan)\n",
    "                p_values.append(np.nan)\n",
    "                continue\n",
    "\n",
    "            ks_stat, p_val = ks_2samp(v1, v2)\n",
    "            ks_stats.append(ks_stat)\n",
    "            p_values.append(p_val)\n",
    "\n",
    "        ks_stats = np.array(ks_stats)\n",
    "        p_values = np.array(p_values)\n",
    "\n",
    "        results[(s1, s2)] = {\n",
    "            \"x\": x_common,\n",
    "            \"ks_stat\": ks_stats,\n",
    "            \"pval\": p_values,\n",
    "        }\n",
    "\n",
    "        if plot:\n",
    "            fig, ax1 = plt.subplots(figsize=(8, 4), dpi=150)\n",
    "            ax1.plot(x_common, ks_stats, label=\"KS statistic\", color=\"tab:blue\", lw=2)\n",
    "            ax1.set_xscale(\"log\")\n",
    "            ax1.set_xlabel(f\"{coord.upper()} (scaled)\")\n",
    "            ax1.set_ylabel(\"KS statistic\", color=\"tab:blue\")\n",
    "            ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "            ax1.grid(True, which=\"both\", ls=\":\")\n",
    "\n",
    "            ax2 = ax1.twinx()\n",
    "            ax2.plot(x_common, p_values, label=\"p-value\", color=\"tab:red\", lw=1.8)\n",
    "            for sig in significance_levels:\n",
    "                ax2.axhline(sig, color=\"gray\", ls=\"--\", lw=0.8, label=f\"p = {sig}\")\n",
    "            ax2.set_ylabel(\"p-value\", color=\"tab:red\")\n",
    "            ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "            ax2.set_yscale(\"log\")\n",
    "\n",
    "            lines, labels = ax1.get_legend_handles_labels()\n",
    "            lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "            ax2.legend(lines + lines2, labels + labels2, loc=\"upper right\")\n",
    "\n",
    "            plt.title(f\"KS Test: {s1} vs {s2}\")\n",
    "            fig.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c17ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_delta_c_norm(suite):\n",
    "    \"\"\"\n",
    "    Load cvir values and compute delta_c_norm = (cvir - median)/std.\n",
    "    \"\"\"\n",
    "    path = os.path.join(base_dir, \"output\", suite, \"halo_concentrations.csv\")\n",
    "    df = pd.read_csv(path)\n",
    "    c = pd.to_numeric(df[\"cvir\"], errors='coerce').dropna()\n",
    "    median_c = c.median()\n",
    "    std_c = c.std()\n",
    "    return ((c - median_c) / std_c).values\n",
    "\n",
    "def load_delta_gamma_norm(suite):\n",
    "    \"\"\"\n",
    "    Load accretion rates and compute delta_gamma_norm = (log10(gamma) - median)/std\n",
    "    only for gamma > 0.\n",
    "    \"\"\"\n",
    "    path = os.path.join(base_dir, \"output\", suite, \"accretion_rates.csv\")\n",
    "    df = pd.read_csv(path)\n",
    "    g = pd.to_numeric(df[\"gamma\"], errors='coerce').dropna()\n",
    "    gpos = g[g > 0]\n",
    "    logg = np.log10(gpos)\n",
    "    median_logg = np.median(logg)\n",
    "    std_logg = np.std(logg)\n",
    "    return ((logg - median_logg) / std_logg).values\n",
    "\n",
    "# === Compute normalized distributions ===\n",
    "delta_c = {suite: load_delta_c_norm(suite) for suite in suite_names}\n",
    "delta_gamma = {suite: load_delta_gamma_norm(suite) for suite in suite_names}\n",
    "\n",
    "# === Pairwise K-S tests ===\n",
    "def ks_test_across_suites(delta_dict, metric_name):\n",
    "    \"\"\"\n",
    "    Perform pairwise two-sample Kolmogorov–Smirnov tests.\n",
    "    Returns a DataFrame of KS statistics and p-values.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for s1, s2 in itertools.combinations(suite_names, 2):\n",
    "        data1 = delta_dict[s1]\n",
    "        data2 = delta_dict[s2]\n",
    "        ks_stat, p_value = ks_2samp(data1, data2)\n",
    "        results.append({\n",
    "            \"Suite 1\": s1,\n",
    "            \"Suite 2\": s2,\n",
    "            f\"KS_{metric_name}_stat\": ks_stat,\n",
    "            f\"p_{metric_name}\": p_value\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "ks_c_df = ks_test_across_suites(delta_c, \"c\")\n",
    "ks_g_df = ks_test_across_suites(delta_gamma, \"gamma\")\n",
    "\n",
    "print(\"Pairwise K-S test results for delta_c_norm:\")\n",
    "print(ks_c_df.to_string(index=False))\n",
    "print(\"\\nPairwise K-S test results for delta_gamma_norm:\")\n",
    "print(ks_g_df.to_string(index=False))\n",
    "\n",
    "# === Visualization functions ===\n",
    "def plot_metric_distributions(delta_dict, metric_label, bins=30):\n",
    "    \"\"\"\n",
    "    Plot overlaid histograms and boxplot of a normalized metric across suites\n",
    "    using the sim_colors palette.\n",
    "    \"\"\"\n",
    "    # Overlaid histograms\n",
    "    plt.figure(figsize=(8, 4), dpi=400)\n",
    "    for suite, data in delta_dict.items():\n",
    "        plt.hist(data, bins=bins, alpha=0.5, label=suite,\n",
    "                 density=True, color=sim_colors[suite])\n",
    "    plt.xlabel(metric_label)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(f\"Overlaid Histograms of {metric_label}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Boxplot comparison\n",
    "    plt.figure(figsize=(8, 4), dpi=400)\n",
    "    bp = plt.boxplot(\n",
    "        [delta_dict[s] for s in suite_names],\n",
    "        labels=suite_names,\n",
    "        showfliers=False,\n",
    "        patch_artist=True\n",
    "    )\n",
    "    # Color each box\n",
    "    for patch, suite in zip(bp['boxes'], suite_names):\n",
    "        patch.set_facecolor(sim_colors[suite])\n",
    "    plt.ylabel(metric_label)\n",
    "    plt.title(f\"Boxplot of {metric_label} Across Suites\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Generate visualizations ===\n",
    "plot_metric_distributions(delta_c, \"Delta c_norm\")\n",
    "plot_metric_distributions(delta_gamma, \"Delta gamma_norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10741822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# === Load and normalize Jeans deviation ===\n",
    "def load_delta_jeans_norm(suite):\n",
    "    path = os.path.join(base_dir, \"output\", suite, \"jeans_deviation_total.csv\")\n",
    "    df = pd.read_csv(path)\n",
    "    dJ = pd.to_numeric(df[\"delta_J_tot\"], errors='coerce').dropna()\n",
    "    return ((dJ - dJ.median()) / dJ.std()).values\n",
    "\n",
    "delta_jeans = {s: load_delta_jeans_norm(s) for s in suite_names}\n",
    "\n",
    "# === Pairwise K-S tests ===\n",
    "def ks_test_across_suites(delta_dict, metric_name):\n",
    "    results = []\n",
    "    for s1, s2 in itertools.combinations(suite_names, 2):\n",
    "        data1 = delta_dict[s1]\n",
    "        data2 = delta_dict[s2]\n",
    "        ks_stat, p_value = ks_2samp(data1, data2)\n",
    "        results.append({\n",
    "            \"Suite 1\": s1,\n",
    "            \"Suite 2\": s2,\n",
    "            f\"KS_{metric_name}_stat\": ks_stat,\n",
    "            f\"p_{metric_name}\": p_value\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "ks_j_df = ks_test_across_suites(delta_jeans, \"jeans_norm\")\n",
    "\n",
    "# === Display K-S test results ===\n",
    "print(\"Pairwise K-S test results for normalized Jeans deviation:\\n\")\n",
    "display(ks_j_df)\n",
    "\n",
    "# === Visualization ===\n",
    "plt.figure(figsize=(8, 4), dpi=400)\n",
    "for suite, data in delta_jeans.items():\n",
    "    plt.hist(data, bins=30, density=True, alpha=0.5,\n",
    "             color=sim_colors[suite], label=suite)\n",
    "plt.xlabel(\"Normalized Jeans Deviation\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Overlaid Histograms of Normalized Jeans Deviation\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 4), dpi=400)\n",
    "bp = plt.boxplot([delta_jeans[s] for s in suite_names],\n",
    "                 labels=suite_names, patch_artist=True, showfliers=False)\n",
    "for patch, suite in zip(bp['boxes'], suite_names):\n",
    "    patch.set_facecolor(sim_colors[suite])\n",
    "plt.ylabel(\"Normalized Jeans Deviation\")\n",
    "plt.title(\"Boxplot of Normalized Jeans Deviation Across Suites\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Astronomy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
