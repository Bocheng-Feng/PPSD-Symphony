{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff7e2b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import symlib \n",
    "import matplotlib.colors as colors\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbdef445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved] Concentration CSV to /Users/fengbocheng/Projects/Symphony-PPSD/output/SymphonyLMC/halo_concentrations.csv\n",
      "[Saved] Concentration CSV to /Users/fengbocheng/Projects/Symphony-PPSD/output/SymphonyMilkyWay/halo_concentrations.csv\n",
      "[Saved] Concentration CSV to /Users/fengbocheng/Projects/Symphony-PPSD/output/SymphonyGroup/halo_concentrations.csv\n",
      "[Saved] Concentration CSV to /Users/fengbocheng/Projects/Symphony-PPSD/output/SymphonyLCluster/halo_concentrations.csv\n"
     ]
    }
   ],
   "source": [
    "def save_concentration(base_dir, suite_name, output):\n",
    "    output_dir = os.path.join(output, \"output\", suite_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    n_halos = symlib.n_hosts(suite_name)\n",
    "    halo_ids, cvir_list = [], []\n",
    "\n",
    "    for halo_idx in range(n_halos):\n",
    "        sim_dir = symlib.get_host_directory(base_dir, suite_name, halo_idx)\n",
    "        try:\n",
    "            r, _ = symlib.read_rockstar(sim_dir)\n",
    "            cvir = r[0, -1][\"cvir\"]\n",
    "            halo_ids.append(halo_idx)\n",
    "            cvir_list.append(cvir)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"[Warning] Rockstar file not found for Halo {halo_idx}\")\n",
    "            continue\n",
    "\n",
    "    df = pd.DataFrame({\"halo_id\": halo_ids, \"cvir\": cvir_list})\n",
    "    df.to_csv(os.path.join(output_dir, \"halo_concentrations.csv\"), index=False)\n",
    "    print(f\"[Saved] Concentration CSV to {output_dir}/halo_concentrations.csv\")\n",
    "\n",
    "save_concentration('/Volumes/Atlas/Symphony', 'SymphonyLMC', \"/Users/fengbocheng/Projects/Symphony-PPSD\")\n",
    "save_concentration('/Volumes/Atlas/Symphony', 'SymphonyMilkyWay', \"/Users/fengbocheng/Projects/Symphony-PPSD\")\n",
    "save_concentration('/Volumes/Expansion/Symphony', 'SymphonyGroup', \"/Users/fengbocheng/Projects/Symphony-PPSD\")\n",
    "save_concentration('/Volumes/Atlas/Symphony', 'SymphonyLCluster', \"/Users/fengbocheng/Projects/Symphony-PPSD\")\n",
    "# save_concentration('/Volumes/Expansion/Symphony', 'SymphonyCluster', \"/Users/fengbocheng/Projects/Symphony-PPSD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0603857d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppsd_profiles(base_dir, suite_name):\n",
    "    # Define input/output directories\n",
    "    density_dir = os.path.join(base_dir, \"output\", suite_name, \"density_profiles\")\n",
    "    mass_dir = os.path.join(base_dir, \"output\", suite_name, \"mass_profiles\")\n",
    "    velocity_dir = os.path.join(base_dir, \"output\", suite_name, \"velocity_profiles\")\n",
    "    output_dir = os.path.join(base_dir, \"output\", suite_name, \"ppsd_profiles\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Collect file names\n",
    "    density_files = sorted([f for f in os.listdir(density_dir) if f.endswith(\".csv\")])\n",
    "    mass_files = sorted([f for f in os.listdir(mass_dir) if f.endswith(\".csv\")])\n",
    "    velocity_files = sorted([f for f in os.listdir(velocity_dir) if f.endswith(\".csv\")])\n",
    "\n",
    "    # Loop through halos and compute Q_r and Q_tot\n",
    "    for i, (f_rho, f_mass, f_vel) in enumerate(zip(density_files, mass_files, velocity_files)):\n",
    "        df_rho = pd.read_csv(os.path.join(density_dir, f_rho))\n",
    "        df_mass = pd.read_csv(os.path.join(mass_dir, f_mass))\n",
    "        df_vel = pd.read_csv(os.path.join(velocity_dir, f_vel))\n",
    "\n",
    "        # Load profile data\n",
    "        r = df_rho[\"r_scaled\"].values\n",
    "        rho = df_rho[\"rho_scaled\"].values\n",
    "        m = df_mass[\"m_scaled\"].values\n",
    "        sigma_rad = df_vel[\"sigma_rad_scaled\"].values\n",
    "        sigma_tot = df_vel[\"sigma_total_scaled\"].values\n",
    "\n",
    "        # Compute pseudo phase-space densities\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            Q_r = np.where(sigma_rad > 0, rho / sigma_rad**3, np.nan)\n",
    "            Q_tot = np.where(sigma_tot > 0, rho / sigma_tot**3, np.nan)\n",
    "\n",
    "        # Save to CSV\n",
    "        df_out = pd.DataFrame({\n",
    "            \"r_scaled\": r,\n",
    "            \"m_scaled\": m,\n",
    "            \"Q_r\": Q_r,\n",
    "            \"Q_tot\": Q_tot\n",
    "        })\n",
    "        df_out.to_csv(os.path.join(output_dir, f\"ppsd_profile_{i}.csv\"), index=False)\n",
    "\n",
    "    print(f\"[Saved] PPSD profiles for {suite_name} saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed59f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ppsd_profiles_colored_by_c(base_dir, suite_name):\n",
    "    \n",
    "    profile_dir = os.path.join(base_dir, \"output\", suite_name, \"ppsd_profiles\")\n",
    "    output_dir = os.path.join(base_dir, \"output\", suite_name, \"figures\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # --- Step 1: Load cvir CSV ---\n",
    "    cvir_path = os.path.join(base_dir, \"output\", suite_name, \"halo_concentrations.csv\")\n",
    "    cvir_df = pd.read_csv(cvir_path)\n",
    "    cvir_dict = dict(zip(cvir_df[\"halo_id\"], cvir_df[\"cvir\"]))\n",
    "\n",
    "    # --- Step 2: Load profiles ---\n",
    "    files = sorted([f for f in os.listdir(profile_dir) if f.endswith(\".csv\")])\n",
    "    ppsd_r, ppsd_tot, mass_profiles, concentrations = [], [], [], []\n",
    "\n",
    "    for f in files:\n",
    "        df = pd.read_csv(os.path.join(profile_dir, f))\n",
    "        r = df[\"r_scaled\"].values\n",
    "        Q_r = df[\"Q_r\"].values\n",
    "        Q_tot = df[\"Q_tot\"].values\n",
    "        m = df[\"m_scaled\"].values\n",
    "        ppsd_r.append(Q_r)\n",
    "        ppsd_tot.append(Q_tot)\n",
    "        mass_profiles.append(m)\n",
    "\n",
    "        # Use halo ID from filename to look up concentration\n",
    "        halo_id = int(f.split(\"_\")[-1].split(\".\")[0])\n",
    "        cvir = cvir_dict.get(halo_id, np.nan)\n",
    "        concentrations.append(cvir)\n",
    "\n",
    "    # Convert to arrays\n",
    "    ppsd_r = np.array(ppsd_r)\n",
    "    ppsd_tot = np.array(ppsd_tot)\n",
    "    mass_profiles = np.array(mass_profiles)\n",
    "    concentrations = np.array(concentrations)\n",
    "    n_halos = len(ppsd_r)\n",
    "\n",
    "    # Compute mean reference curves (Qr_ref, Qtot_ref ∝ r^-1.875)\n",
    "    mean_Qr = np.nanmean(ppsd_r, axis=0)\n",
    "    mean_Qtot = np.nanmean(ppsd_tot, axis=0)\n",
    "    valid_r = ~np.isnan(mean_Qr)\n",
    "    valid_tot = ~np.isnan(mean_Qtot)\n",
    "\n",
    "    log_r = np.log(r[valid_r])\n",
    "    log_Qr = np.log(mean_Qr[valid_r])\n",
    "    A_r = np.exp(np.mean(log_Qr + 1.875 * log_r))\n",
    "    log_Qtot = np.log(mean_Qtot[valid_tot])\n",
    "    A_tot = np.exp(np.mean(log_Qtot + 1.875 * np.log(r[valid_tot])))\n",
    "\n",
    "    ref_curve_r = A_r * r**(-1.875)\n",
    "    ref_curve_tot = A_tot * r**(-1.875)\n",
    "\n",
    "    # Compute residuals for each halo\n",
    "    residuals_r, residuals_tot = [], []\n",
    "    for i in range(n_halos):\n",
    "        Qr = ppsd_r[i]\n",
    "        Qt = ppsd_tot[i]\n",
    "        res_r = np.full_like(Qr, np.nan)\n",
    "        res_t = np.full_like(Qt, np.nan)\n",
    "        idx_r = ~np.isnan(Qr)\n",
    "        idx_t = ~np.isnan(Qt)\n",
    "        if np.any(idx_r):\n",
    "            res_r[idx_r] = np.log10(Qr[idx_r]) - np.log10(ref_curve_r[idx_r])\n",
    "        if np.any(idx_t):\n",
    "            res_t[idx_t] = np.log10(Qt[idx_t]) - np.log10(ref_curve_tot[idx_t])\n",
    "        residuals_r.append(res_r)\n",
    "        residuals_tot.append(res_t)\n",
    "\n",
    "    # Convert residuals to arrays and compute stats\n",
    "    residuals_r = np.array(residuals_r)\n",
    "    residuals_tot = np.array(residuals_tot)\n",
    "    mean_res_r = np.nanmean(residuals_r, axis=0)\n",
    "    std_res_r = np.nanstd(residuals_r, axis=0)\n",
    "    mean_res_tot = np.nanmean(residuals_tot, axis=0)\n",
    "    std_res_tot = np.nanstd(residuals_tot, axis=0)\n",
    "\n",
    "    # Set up colormap for cvir\n",
    "    cmap = cm.viridis\n",
    "    norm = plt.Normalize(vmin=np.nanmin(concentrations), vmax=np.nanmax(concentrations))\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "\n",
    "    # --- Figure 1: Q vs r ---\n",
    "    fig1, ax1 = plt.subplots(1, 2, figsize=(14, 5), dpi=500, constrained_layout=True)\n",
    "    for i in range(n_halos):\n",
    "        ax1[0].plot(r, ppsd_r[i], color=cmap(norm(concentrations[i])), lw=0.7)\n",
    "        ax1[1].plot(r, ppsd_tot[i], color=cmap(norm(concentrations[i])), lw=0.7)\n",
    "    ax1[0].set(title=r\"$Q_r$ vs $r$\", xscale=\"log\", yscale=\"log\",\n",
    "               xlabel=r\"$r / r_{\\rm vir}$\", ylabel=r\"$Q_r$\")\n",
    "    ax1[1].set(title=r\"$Q_{\\rm tot}$ vs $r$\", xscale=\"log\", yscale=\"log\",\n",
    "               xlabel=r\"$r / r_{\\rm vir}$\", ylabel=r\"$Q_{\\rm tot}$\")\n",
    "    for ax in ax1: ax.grid(True, which=\"both\", linestyle=\":\")\n",
    "    fig1.colorbar(sm, ax=ax1.ravel().tolist(), shrink=0.9).set_label(r\"$c_{\\rm vir}$\")\n",
    "    fig1.suptitle(f\"PPSD vs r (Colored by c): {suite_name}\")\n",
    "    fig1.savefig(os.path.join(output_dir, \"PPSD_vs_r (colored by c).png\"))\n",
    "    plt.show()\n",
    "    plt.close(fig1)\n",
    "\n",
    "    # --- Figure 2: Q vs M(<r) ---\n",
    "    fig2, ax2 = plt.subplots(1, 2, figsize=(14, 5), dpi=500, constrained_layout=True)\n",
    "    for i in range(n_halos):\n",
    "        ax2[0].plot(mass_profiles[i], ppsd_r[i], color=cmap(norm(concentrations[i])), lw=0.7)\n",
    "        ax2[1].plot(mass_profiles[i], ppsd_tot[i], color=cmap(norm(concentrations[i])), lw=0.7)\n",
    "    ax2[0].set(title=r\"$Q_r$ vs $M(<r)$\", xscale=\"log\", yscale=\"log\",\n",
    "               xlabel=r\"$M(<r)/M_{\\rm vir}$\", ylabel=r\"$Q_r$\")\n",
    "    ax2[1].set(title=r\"$Q_{\\rm tot}$ vs $M(<r)$\", xscale=\"log\", yscale=\"log\",\n",
    "               xlabel=r\"$M(<r)/M_{\\rm vir}$\", ylabel=r\"$Q_{\\rm tot}$\")\n",
    "    for ax in ax2: ax.grid(True, which=\"both\", linestyle=\":\")\n",
    "    fig2.colorbar(sm, ax=ax2.ravel().tolist(), shrink=0.9).set_label(r\"$c_{\\rm vir}$\")\n",
    "    fig2.suptitle(f\"PPSD vs Mass (Colored by c): {suite_name}\")\n",
    "    fig2.savefig(os.path.join(output_dir, \"PPSD_vs_mass (colored by c).png\"))\n",
    "    plt.show()\n",
    "    plt.close(fig2)\n",
    "\n",
    "    # --- Figure 3: Residuals ---\n",
    "    fig3, ax3 = plt.subplots(1, 2, figsize=(14, 5), dpi=500, constrained_layout=True)\n",
    "    for i in range(n_halos):\n",
    "        ax3[0].plot(r, residuals_r[i], color=cmap(norm(concentrations[i])), lw=0.7)\n",
    "        ax3[1].plot(r, residuals_tot[i], color=cmap(norm(concentrations[i])), lw=0.7)\n",
    "    # Add mean ± 1σ lines\n",
    "    ax3[0].plot(r, mean_res_r, 'k-', lw=1)\n",
    "    ax3[0].fill_between(r, mean_res_r - std_res_r, mean_res_r + std_res_r, color='gray', alpha=0.3)\n",
    "    ax3[0].axhline(0, color='r', linestyle='--', lw=1)\n",
    "    ax3[0].set(title=r\"$\\log_{10}(Q_r/Q_{\\rm ref})$ vs $r / r_{\\rm vir}$\",\n",
    "               xlabel=r\"$r / r_{\\rm vir}$\", ylabel=r\"$\\log_{10}(Q_r/Q_{\\rm ref})$\",\n",
    "               xscale=\"log\", ylim=(-1.5, 1.5))\n",
    "    ax3[1].plot(r, mean_res_tot, 'k-', lw=1)\n",
    "    ax3[1].fill_between(r, mean_res_tot - std_res_tot, mean_res_tot + std_res_tot, color='gray', alpha=0.3)\n",
    "    ax3[1].axhline(0, color='r', linestyle='--', lw=1)\n",
    "    ax3[1].set(title=r\"$\\log_{10}(Q_{\\rm tot}/Q_{\\rm ref})$ vs $r / r_{\\rm vir}$\",\n",
    "               xlabel=r\"$r / r_{\\rm vir}$\", ylabel=r\"$\\log_{10}(Q_{\\rm tot}/Q_{\\rm ref})$\",\n",
    "               xscale=\"log\", ylim=(-1.5, 1.5))\n",
    "    for ax in ax3: ax.grid(True, which=\"both\", linestyle=\":\")\n",
    "    fig3.colorbar(sm, ax=ax3.ravel().tolist(), shrink=0.9).set_label(r\"$c_{\\rm vir}$\")\n",
    "    fig3.suptitle(f\"PPSD Residuals (Colored by c): {suite_name}\")\n",
    "    fig3.savefig(os.path.join(output_dir, \"PPSD_residuals (colored by c).png\"))\n",
    "    plt.show()\n",
    "    plt.close(fig3)\n",
    "\n",
    "    print(\"[Saved] Colored PPSD Figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce1bdbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_density_colored_by_c(base_dir, suite_name): \n",
    "   # Load concentration CSV\n",
    "    cvir_path = os.path.join(base_dir, \"output\", suite_name, \"halo_concentrations.csv\")\n",
    "    if not os.path.exists(cvir_path):\n",
    "        print(f\"[Error] Concentration file not found: {cvir_path}\")\n",
    "        return\n",
    "    cvir_df = pd.read_csv(cvir_path)\n",
    "    cvir_dict = dict(zip(cvir_df[\"halo_id\"], cvir_df[\"cvir\"]))\n",
    "\n",
    "    # Load density profile CSVs\n",
    "    profile_dir = os.path.join(base_dir, \"output\", suite_name, \"density_profiles\")\n",
    "    file_list = sorted(glob(os.path.join(profile_dir, \"halo_*_profile.csv\")))\n",
    "    n_halos = len(file_list)\n",
    "    if n_halos == 0:\n",
    "        print(\"[Error] No profile files found.\")\n",
    "        return\n",
    "\n",
    "    # Prepare arrays\n",
    "    all_profiles = []\n",
    "    r_scaled_list = []\n",
    "    c_vir_list = []\n",
    "\n",
    "    for file in file_list:\n",
    "        df = pd.read_csv(file)\n",
    "        df[\"rho_r2\"] = df[\"rho_scaled\"] * df[\"r_scaled\"]**2\n",
    "        all_profiles.append(df[\"rho_r2\"].values)\n",
    "        r_scaled_list.append(df[\"r_scaled\"].values)\n",
    "\n",
    "        halo_id = int(file.split(\"_\")[-2])  # Assumes name like halo_005_profile.csv\n",
    "        c_vir = cvir_dict.get(halo_id, np.nan)\n",
    "        c_vir_list.append(c_vir)\n",
    "\n",
    "    c_vir_arr = np.array(c_vir_list)\n",
    "    cmap = cm.viridis\n",
    "    norm = plt.Normalize(vmin=np.nanmin(c_vir_arr), vmax=np.nanmax(c_vir_arr))\n",
    "    sm = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "    # Create output directory\n",
    "    fig_dir = os.path.join(base_dir, \"output\", suite_name, \"figures\")\n",
    "    os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "    # -------- Plot: All profiles colored by c_vir --------\n",
    "    fig, ax = plt.subplots(figsize=(6.5, 5), dpi=500)\n",
    "    for rho_r2, r, c in zip(all_profiles, r_scaled_list, c_vir_arr):\n",
    "        ax.plot(r, rho_r2, color=cmap(norm(c)), lw=0.7, alpha=0.8)\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_xlabel(r\"$r / r_{\\mathrm{vir}}$\")\n",
    "    ax.set_ylabel(r\"$(\\rho/\\bar{\\rho}_m) \\cdot (r/r_{\\mathrm{vir}})^2$\")\n",
    "    ax.grid(True, which=\"both\", linestyle=\":\")\n",
    "    ax.set_title(f\"Density Profiles Colored by $c$ ({suite_name})\")\n",
    "\n",
    "    cbar = fig.colorbar(sm, ax=ax, pad=0.01)\n",
    "    cbar.set_label(r\"$c_{\\rm vir}$\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(fig_dir, \"density_profiles (colored by c).png\"))\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"[Done] Colored density profiles saved to {fig_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5312a2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_velocity_colored_by_c(base_dir, suite_name):\n",
    "    input_dir = os.path.join(base_dir, \"output\", suite_name, \"velocity_profiles\")\n",
    "    output_dir = os.path.join(base_dir, \"output\", suite_name, \"figures\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load cvir CSV\n",
    "    cvir_path = os.path.join(base_dir, \"output\", suite_name, \"halo_concentrations.csv\")\n",
    "    if not os.path.exists(cvir_path):\n",
    "        print(f\"[Error] Concentration file not found: {cvir_path}\")\n",
    "        return\n",
    "    cvir_df = pd.read_csv(cvir_path)\n",
    "    cvir_dict = dict(zip(cvir_df[\"halo_id\"], cvir_df[\"cvir\"]))\n",
    "\n",
    "    # Load velocity profiles\n",
    "    files = sorted([f for f in os.listdir(input_dir) if f.endswith(\".csv\")])\n",
    "    if not files:\n",
    "        print(\"[Error] No velocity profile files found.\")\n",
    "        return\n",
    "\n",
    "    r = pd.read_csv(os.path.join(input_dir, files[0]))[\"r_scaled\"].values\n",
    "    sigma_rad_all, sigma_tan_all, sigma_total_all, beta_all, cvir_all = [], [], [], [], []\n",
    "\n",
    "    for f in files:\n",
    "        df = pd.read_csv(os.path.join(input_dir, f))\n",
    "        sigma_rad_all.append(df[\"sigma_rad_scaled\"].values)\n",
    "        sigma_tan_all.append(df[\"sigma_tan_scaled\"].values)\n",
    "        sigma_total_all.append(df[\"sigma_total_scaled\"].values)\n",
    "        beta_all.append(df[\"beta\"].values)\n",
    "\n",
    "        # Extract halo ID from filename\n",
    "        import re\n",
    "        match = re.search(r\"halo_(\\d+)\", f)\n",
    "        halo_id = int(match.group(1))\n",
    "        cvir = cvir_dict.get(halo_id, np.nan)\n",
    "        cvir_all.append(cvir)\n",
    "\n",
    "    # Convert and normalize colors\n",
    "    cvir_arr = np.array(cvir_all)\n",
    "    cmap = cm.viridis\n",
    "    norm = plt.Normalize(vmin=np.nanmin(cvir_arr), vmax=np.nanmax(cvir_arr))\n",
    "    sm = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "    # Prepare plotting arrays\n",
    "    data_arrs = [sigma_rad_all, sigma_tan_all, sigma_total_all, beta_all]\n",
    "    titles = [r\"$\\sigma_{\\mathrm{rad}} / V_{\\mathrm{vir}}$\", \n",
    "              r\"$\\sigma_{\\mathrm{tan}} / V_{\\mathrm{vir}}$\",\n",
    "              r\"$\\sigma_{\\mathrm{total}} / V_{\\mathrm{vir}}$\",\n",
    "              r\"$\\beta$\"]\n",
    "\n",
    "    # Plot 4 stacked velocity-related profiles\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(7, 10), sharex=True, dpi=500, constrained_layout=True)\n",
    "    for i in range(4):\n",
    "        for y, c in zip(data_arrs[i], cvir_arr):\n",
    "            axes[i].plot(r, y, color=cmap(norm(c)), lw=0.7, alpha=0.8)\n",
    "        axes[i].set_ylabel(titles[i])\n",
    "        axes[i].set_xscale(\"log\")\n",
    "        axes[i].grid(True, which=\"both\", linestyle=\":\")\n",
    "        \n",
    "    axes[-1].set_ylim(-1, 1)\n",
    "    axes[-1].set_xlabel(r\"$r / r_{\\mathrm{vir}}$\")\n",
    "    fig.suptitle(f\"Velocity Profiles Colored by $c$ ({suite_name})\", fontsize=14)\n",
    "    cbar = fig.colorbar(sm, ax=axes.ravel().tolist(), pad=0.01)\n",
    "    cbar.set_label(r\"$c_{\\rm vir}$\")\n",
    "\n",
    "    fig.savefig(os.path.join(output_dir, \"velocity_profiles (colored_by_c).png\"))\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"[Saved] Velocity profiles with concentration coloring saved for {suite_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e7cfe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynumdiff\n",
    "import pynumdiff.optimize\n",
    "\n",
    "def get_diff_and_optimize_funcs(method):\n",
    "    submodules = [\n",
    "        'kalman_smooth',\n",
    "        'smooth_finite_difference',\n",
    "        'finite_difference',\n",
    "        'total_variation_regularization',\n",
    "        'linear_model'\n",
    "    ]\n",
    "    for submod in submodules:\n",
    "        try:\n",
    "            mod_optimize = getattr(pynumdiff.optimize, submod)\n",
    "            mod_diff = getattr(pynumdiff, submod)\n",
    "            if hasattr(mod_optimize, method) and hasattr(mod_diff, method):\n",
    "                return getattr(mod_diff, method), getattr(mod_optimize, method)\n",
    "        except AttributeError:\n",
    "            continue\n",
    "    raise ValueError(f\"Method '{method}' not found in any submodule.\")\n",
    "\n",
    "def fit_and_save_ppsd_slopes(base_dir, suite_name, method='constant_jerk', tvgamma=None):\n",
    "    # Paths\n",
    "    density_dir = os.path.join(base_dir, \"output\", suite_name, \"density_profiles\")\n",
    "    velocity_dir = os.path.join(base_dir, \"output\", suite_name, \"velocity_profiles\")\n",
    "    mass_dir = os.path.join(base_dir, \"output\", suite_name, \"mass_profiles\")\n",
    "    slope_r_dir = os.path.join(base_dir, \"output\", suite_name, \"ppsd_slope_profiles_r\")\n",
    "    slope_m_dir = os.path.join(base_dir, \"output\", suite_name, \"ppsd_slope_profiles_m\")\n",
    "    os.makedirs(slope_r_dir, exist_ok=True)\n",
    "    os.makedirs(slope_m_dir, exist_ok=True)\n",
    "\n",
    "    density_files = sorted([f for f in os.listdir(density_dir) if f.endswith(\".csv\")])\n",
    "    velocity_files = sorted([f for f in os.listdir(velocity_dir) if f.endswith(\".csv\")])\n",
    "    mass_files = sorted([f for f in os.listdir(mass_dir) if f.endswith(\".csv\")])\n",
    "    n_halos = len(density_files)\n",
    "\n",
    "    def fit_derivative(y, dt):\n",
    "        try:\n",
    "            diff_func, optimize_func = get_diff_and_optimize_funcs(method)\n",
    "            kwargs = {'tvgamma': tvgamma} if 'tvgamma' in optimize_func.__code__.co_varnames else {}\n",
    "            params, _ = optimize_func(y, dt, **kwargs)\n",
    "            _, dydx = diff_func(y, dt, params)\n",
    "            return dydx\n",
    "        except Exception as e:\n",
    "            print(f\"{method} derivative fit failed: {e}\")\n",
    "            return None\n",
    "\n",
    "    for i in range(n_halos):\n",
    "        try:\n",
    "            df_rho = pd.read_csv(os.path.join(density_dir, density_files[i]))\n",
    "            df_vel = pd.read_csv(os.path.join(velocity_dir, velocity_files[i]))\n",
    "            df_mass = pd.read_csv(os.path.join(mass_dir, mass_files[i]))\n",
    "        except Exception as e:\n",
    "            print(f\"[Halo {i}] loading profiles failed: {e}\")\n",
    "            continue\n",
    "\n",
    "        r = df_rho[\"r_scaled\"].values\n",
    "        m = df_mass[\"m_scaled\"].values\n",
    "        rho = df_rho[\"rho_scaled\"].values\n",
    "        sigma_tot = df_vel[\"sigma_total_scaled\"].values\n",
    "        sigma_rad = df_vel[\"sigma_rad_scaled\"].values\n",
    "\n",
    "        dt_r = np.diff(np.log10(r)).mean()\n",
    "        dt_m = np.diff(np.log10(m)).mean()\n",
    "\n",
    "        log_rho = np.log10(rho)\n",
    "        log_sigma_tot = np.log10(sigma_tot)\n",
    "        log_sigma_rad = np.log10(sigma_rad)\n",
    "\n",
    "        drho_dlogr = fit_derivative(log_rho, dt_r)\n",
    "        dsigma_tot_dlogr = fit_derivative(log_sigma_tot, dt_r)\n",
    "        dsigma_rad_dlogr = fit_derivative(log_sigma_rad, dt_r)\n",
    "\n",
    "        drho_dlogm = fit_derivative(log_rho, dt_m)\n",
    "        dsigma_tot_dlogm = fit_derivative(log_sigma_tot, dt_m)\n",
    "        dsigma_rad_dlogm = fit_derivative(log_sigma_rad, dt_m)\n",
    "\n",
    "        if None in [drho_dlogr, dsigma_tot_dlogr, dsigma_rad_dlogr, drho_dlogm, dsigma_tot_dlogm, dsigma_rad_dlogm]:\n",
    "            print(f\"[Halo {i}] derivative fitting failed, skipping\")\n",
    "            continue\n",
    "\n",
    "        slope_Q_tot_r = drho_dlogr - 3 * dsigma_tot_dlogr\n",
    "        slope_Q_rad_r = drho_dlogr - 3 * dsigma_rad_dlogr\n",
    "        slope_Q_tot_m = drho_dlogm - 3 * dsigma_tot_dlogm\n",
    "        slope_Q_rad_m = drho_dlogm - 3 * dsigma_rad_dlogm\n",
    "\n",
    "        df_r = pd.DataFrame({\"r_scaled\": r, \"slope_Q_r\": slope_Q_rad_r, \"slope_Q_tot\": slope_Q_tot_r})\n",
    "        df_m = pd.DataFrame({\"m_scaled\": m, \"slope_Q_r\": slope_Q_rad_m, \"slope_Q_tot\": slope_Q_tot_m})\n",
    "\n",
    "        df_r.to_csv(os.path.join(slope_r_dir, f\"slope_profile_r_{i}.csv\"), index=False)\n",
    "        df_m.to_csv(os.path.join(slope_m_dir, f\"slope_profile_m_{i}.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59e5ef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ppsd_slope_colored_by_c(base_dir, suite_name):\n",
    "    slope_r_dir = os.path.join(base_dir, \"output\", suite_name, \"ppsd_slope_profiles_r\")\n",
    "    slope_m_dir = os.path.join(base_dir, \"output\", suite_name, \"ppsd_slope_profiles_m\")\n",
    "    output_dir = os.path.join(base_dir, \"output\", suite_name, \"figures\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    slope_r_files = sorted([f for f in os.listdir(slope_r_dir) if f.endswith(\".csv\")])\n",
    "    slope_m_files = sorted([f for f in os.listdir(slope_m_dir) if f.endswith(\".csv\")])\n",
    "    n_halos = len(slope_r_files)\n",
    "\n",
    "    concentrations = []\n",
    "    for i in range(n_halos):\n",
    "        sim_dir = symlib.get_host_directory(base_dir, suite_name, i)\n",
    "        try:\n",
    "            r_data, _ = symlib.read_rockstar(sim_dir)\n",
    "            cvir_val = r_data[0, -1][\"cvir\"]\n",
    "        except Exception as e:\n",
    "            print(f\"[Halo {i}] concentration failed: {e}\")\n",
    "            cvir_val = np.nan\n",
    "        concentrations.append(cvir_val)\n",
    "    concentrations = np.array(concentrations)\n",
    "\n",
    "    cmap = cm.viridis\n",
    "    norm = colors.Normalize(vmin=np.nanmin(concentrations), vmax=np.nanmax(concentrations))\n",
    "    sm = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "    fig1, axes1 = plt.subplots(1, 2, figsize=(13, 5), dpi=500, constrained_layout=True)\n",
    "    fig2, axes2 = plt.subplots(1, 2, figsize=(13, 5), dpi=500, constrained_layout=True)\n",
    "    ax_slope_tot, ax_slope_rad = axes1\n",
    "    ax_slope_tot_m, ax_slope_rad_m = axes2\n",
    "\n",
    "    for i in range(n_halos):\n",
    "        try:\n",
    "            df_r = pd.read_csv(os.path.join(slope_r_dir, slope_r_files[i]))\n",
    "            df_m = pd.read_csv(os.path.join(slope_m_dir, slope_m_files[i]))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        r = df_r[\"r_scaled\"].values\n",
    "        m = df_m[\"m_scaled\"].values\n",
    "        slope_Q_tot_r = df_r[\"slope_Q_tot\"].values\n",
    "        slope_Q_rad_r = df_r[\"slope_Q_r\"].values\n",
    "        slope_Q_tot_m = df_m[\"slope_Q_tot\"].values\n",
    "        slope_Q_rad_m = df_m[\"slope_Q_r\"].values\n",
    "\n",
    "        color = cmap(norm(concentrations[i])) if np.isfinite(concentrations[i]) else \"gray\"\n",
    "        ax_slope_tot.plot(r, slope_Q_tot_r, color=color, alpha=0.5, lw=0.5)\n",
    "        ax_slope_rad.plot(r, slope_Q_rad_r, color=color, alpha=0.5, lw=0.5)\n",
    "        ax_slope_tot_m.plot(m, slope_Q_tot_m, color=color, alpha=0.5, lw=0.5)\n",
    "        ax_slope_rad_m.plot(m, slope_Q_rad_m, color=color, alpha=0.5, lw=0.5)\n",
    "\n",
    "    for ax, label, xscale in zip(\n",
    "        [ax_slope_tot, ax_slope_rad],\n",
    "        [r\"$\\mathrm{d}\\log Q / \\mathrm{d}\\log r$\", r\"$\\mathrm{d}\\log Q_r / \\mathrm{d}\\log r$\"],\n",
    "        [\"log\", \"log\"]):\n",
    "        ax.set_xlabel(r\"$r / R_\\mathrm{vir}$\")\n",
    "        ax.set_ylabel(label)\n",
    "        ax.set_xscale(xscale)\n",
    "        ax.set_ylim(-4, 1)\n",
    "        ax.axhline(-1.875, color='k', ls='--', lw=0.7)\n",
    "        ax.grid(True, which=\"both\", linestyle=\":\")\n",
    "\n",
    "    for ax, label in zip([ax_slope_tot_m, ax_slope_rad_m],\n",
    "                         [r\"$\\mathrm{d}\\log Q / \\mathrm{d}\\log M$\", r\"$\\mathrm{d}\\log Q_r / \\mathrm{d}\\log M$\"]):\n",
    "        ax.set_xlabel(r\"$M(<r) / M_\\mathrm{vir}$\")\n",
    "        ax.set_ylabel(label)\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_ylim(-4, 1)\n",
    "        ax.grid(True, which=\"both\", linestyle=\":\")\n",
    "\n",
    "    fig1.colorbar(sm, ax=axes1.ravel().tolist(), shrink=0.9).set_label(r\"$c_\\mathrm{vir}$\")\n",
    "    fig2.colorbar(sm, ax=axes2.ravel().tolist(), shrink=0.9).set_label(r\"$c_\\mathrm{vir}$\")\n",
    "\n",
    "    fig1.savefig(os.path.join(output_dir, f\"PPSD_slopes_r_colored_by_c.png\"))\n",
    "    fig2.savefig(os.path.join(output_dir, f\"PPSD_slopes_m_colored_by_c.png\"))\n",
    "    plt.show()\n",
    "    plt.close(fig1)\n",
    "    plt.close(fig2)\n",
    "\n",
    "    print(\"[Saved] slope plots colored by c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7817f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved] PPSD profiles for SymphonyLMC saved to /Users/fengbocheng/Projects/Symphony-PPSD/output/SymphonyLMC/ppsd_profiles\n",
      "[Saved] PPSD profiles for SymphonyMilkyWay saved to /Users/fengbocheng/Projects/Symphony-PPSD/output/SymphonyMilkyWay/ppsd_profiles\n",
      "[Saved] PPSD profiles for SymphonyGroup saved to /Users/fengbocheng/Projects/Symphony-PPSD/output/SymphonyGroup/ppsd_profiles\n",
      "[Saved] PPSD profiles for SymphonyLCluster saved to /Users/fengbocheng/Projects/Symphony-PPSD/output/SymphonyLCluster/ppsd_profiles\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/Users/fengbocheng/Projects/Symphony-PPSD\"\n",
    "suite_names = [\n",
    "    \"SymphonyLMC\",\n",
    "    \"SymphonyMilkyWay\",\n",
    "    \"SymphonyGroup\",\n",
    "    \"SymphonyLCluster\",\n",
    "]\n",
    "\n",
    "for suite in suite_names:\n",
    "    ppsd_profiles(base_dir, suite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d46351",
   "metadata": {},
   "outputs": [],
   "source": [
    "for suite in suite_names:\n",
    "    plot_ppsd_profiles_colored_by_c(base_dir, suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06e2a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for suite in suite_names:\n",
    "    plot_density_colored_by_c(base_dir, suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381cdf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for suite in suite_names:\n",
    "    plot_velocity_colored_by_c(base_dir, suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdae881",
   "metadata": {},
   "outputs": [],
   "source": [
    "for suite in suite_names:\n",
    "    fit_and_save_ppsd_slopes(base_dir, suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148fd9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for suite in suite_names:\n",
    "    plot_ppsd_slope_colored_by_c(base_dir, suite)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Astronomy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
