{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61a75d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy.constants import G\n",
    "from astropy import units as u\n",
    "from scipy.integrate import quad\n",
    "import symlib\n",
    "import os\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.optimize import curve_fit   \n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.integrate import cumulative_trapezoid as cumtrapz\n",
    "\n",
    "base_dir='/Users/fengbocheng/Projects/Symphony-PPSD/output/z_0'\n",
    "suite_names = [\"SymphonyLMC\", \"SymphonyMilkyWay\", \"SymphonyGroup\", \"SymphonyLCluster\", \"SymphonyCluster\"]\n",
    "sim_colors = {\n",
    "        \"SymphonyLMC\": sns.color_palette(\"colorblind\")[4],\n",
    "        \"SymphonyMilkyWay\": sns.color_palette(\"colorblind\")[0],\n",
    "        \"SymphonyGroup\": sns.color_palette(\"colorblind\")[2],\n",
    "        \"SymphonyLCluster\": sns.color_palette(\"colorblind\")[1],\n",
    "        \"SymphonyCluster\": sns.color_palette(\"colorblind\")[3],\n",
    "    }\n",
    "sim_names = {\n",
    "        \"SymphonyLMC\": \"LMC\",\n",
    "        \"SymphonyMilkyWay\": \"Milky~Way\",\n",
    "        \"SymphonyGroup\": \"Group\",\n",
    "        \"SymphonyLCluster\": \"L-Cluster\",\n",
    "        \"SymphonyCluster\": \"Cluster\",\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac967aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_delta_J_cumulative(r, delta_J, r_max=1.0):\n",
    "    r = np.asarray(r, dtype=float)\n",
    "    dJ = np.asarray(delta_J, dtype=float)\n",
    "    mask = np.isfinite(r) & np.isfinite(dJ) & (r > 0) & (r <= r_max)\n",
    "    if mask.sum() < 3:\n",
    "        return None, None\n",
    "    r, dJ = r[mask], dJ[mask]\n",
    "    if not np.all(np.diff(r) > 0):\n",
    "        idx = np.argsort(r)\n",
    "        r, dJ = r[idx], dJ[idx]\n",
    "    J_cum = cumtrapz(dJ, r, initial=0.0)\n",
    "    return r, J_cum\n",
    "\n",
    "def plot_mean_cumulative_jeans_deviation_normalized(\n",
    "    base_dir, suite_names, jeans_dir_name=\"jeans_deviation\",\n",
    "    r_max=1.0, n_grid=128, use_median=False\n",
    "):\n",
    "    plt.figure(figsize=(7,6), dpi=500)\n",
    "\n",
    "    for suite in suite_names:\n",
    "        jdir = os.path.join(base_dir, \"data\", suite, jeans_dir_name)\n",
    "        files = sorted([f for f in os.listdir(jdir) if f.endswith(\".csv\")])\n",
    "\n",
    "        per_halo_r, per_halo_Jn = [], []\n",
    "\n",
    "        for f in files:\n",
    "            df = pd.read_csv(os.path.join(jdir, f))\n",
    "            r  = pd.to_numeric(df[\"r_scaled\"], errors=\"coerce\").values\n",
    "            dJ = pd.to_numeric(df[\"delta_J\"],  errors=\"coerce\").values\n",
    "\n",
    "            r_cut, J_cum = compute_delta_J_cumulative(r, dJ, r_max=r_max)\n",
    "            if r_cut is None:\n",
    "                continue\n",
    "            J_end = J_cum[-1]\n",
    "            if not np.isfinite(J_end) or J_end == 0:\n",
    "                continue\n",
    "            J_norm = J_cum / J_end  # normalize by ΔJ_tot(<r_max)\n",
    "            per_halo_r.append(r_cut)\n",
    "            per_halo_Jn.append(J_norm)\n",
    "\n",
    "        if len(per_halo_r) == 0:\n",
    "            continue\n",
    "\n",
    "        # Common log-radius grid (intersection)\n",
    "        rmin = max(r_.min() for r_ in per_halo_r)\n",
    "        rmax = min(r_.max() for r_ in per_halo_r)\n",
    "        if not (np.isfinite(rmin) and np.isfinite(rmax) and rmax > rmin):\n",
    "            continue\n",
    "        r_grid = np.logspace(np.log10(rmin), np.log10(rmax), n_grid)\n",
    "\n",
    "        # Interpolate normalized curves to common grid\n",
    "        stack = []\n",
    "        for r_, Jn_ in zip(per_halo_r, per_halo_Jn):\n",
    "            y = np.full_like(r_grid, np.nan, dtype=float)\n",
    "            inside = (r_grid >= r_.min()) & (r_grid <= r_.max())\n",
    "            if inside.any():\n",
    "                y[inside] = np.interp(np.log10(r_grid[inside]), np.log10(r_), Jn_)\n",
    "            stack.append(y)\n",
    "        Y = np.vstack(stack)\n",
    "\n",
    "        # Center and spread\n",
    "        if use_median:\n",
    "            center = np.nanmedian(Y, axis=0)\n",
    "            spread = 1.4826 * np.nanmedian(np.abs(Y - center), axis=0)\n",
    "        else:\n",
    "            center = np.nanmean(Y, axis=0)\n",
    "            spread = np.nanstd(Y, axis=0)\n",
    "\n",
    "        plt.plot(r_grid, center, lw=2.0, color=sim_colors[suite], label=suite)\n",
    "        #plt.fill_between(r_grid, center - spread, center + spread, color=sim_colors[suite], alpha=0.25)\n",
    "\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlabel(r\"$r / R_{\\rm vir}$\", fontsize=14)\n",
    "    plt.ylabel(r\"$\\delta_J(<r)/\\delta_J(<R_{\\mathrm{vir}})$\", fontsize=14)\n",
    "    plt.grid(True, ls=\":\", alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_mean_cumulative_jeans_deviation_normalized(base_dir, suite_names, r_max=1.0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e98301",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = 1 \n",
    "def sci_notation_latex(x, precision=2):\n",
    "\n",
    "    fmt = f\"{x:.{precision}e}\"\n",
    "    base, exponent = fmt.split(\"e\")\n",
    "    return rf\"{base} \\times 10^{{{int(exponent)}}}\"\n",
    "\n",
    "def compute_eta_from_scaled_profiles(r, rho, m_enc, sigma_tot, r_max=1.0):\n",
    "    r = np.asarray(r); rho = np.asarray(rho)\n",
    "    m_enc = np.asarray(m_enc); sigma_tot = np.asarray(sigma_tot)\n",
    "\n",
    "    # mask: finite, r>0, within r_max\n",
    "    mask = (np.isfinite(r) & np.isfinite(rho) &\n",
    "            np.isfinite(m_enc) & np.isfinite(sigma_tot) &\n",
    "            (r > 0) & (r <= r_max))\n",
    "\n",
    "    r, rho, m_enc, sigma_tot = r[mask], rho[mask], m_enc[mask], sigma_tot[mask]\n",
    "\n",
    "    # shell integrands (dV = 4π r^2 dr)\n",
    "    vol_shell = 4.0 * np.pi * r**2\n",
    "    K_shell = 0.5 * rho * (sigma_tot**2) * vol_shell\n",
    "    U_shell = -G * m_enc * rho / r * vol_shell\n",
    "\n",
    "    # cumulative integrals\n",
    "    K_cum = cumtrapz(K_shell, r, initial=0.0)\n",
    "    U_cum = cumtrapz(U_shell, r, initial=0.0)\n",
    "\n",
    "    # last valid point within r_max\n",
    "    if not np.isfinite(U_cum[-1]) or U_cum[-1] == 0 or K_cum[-1] <= 0:\n",
    "        return np.nan\n",
    "\n",
    "    return 2.0 * K_cum[-1] / abs(U_cum[-1])\n",
    "\n",
    "def compare_normalized_jeans_deviation_vs_virial_ratio():\n",
    "\n",
    "    delta_J_list = []\n",
    "    eta_list     = []\n",
    "    mass_list    = []\n",
    "\n",
    "    # 1) Gather raw δJ, η, and M_vir for all halos\n",
    "    for suite in suite_names:\n",
    "        density_dir = os.path.join(base_dir, \"data\", suite, \"density_profiles\")\n",
    "        velocity_dir = os.path.join(base_dir, \"data\", suite, \"velocity_profiles\")\n",
    "        mass_dir    = os.path.join(base_dir, \"data\", suite, \"mass_profiles\")\n",
    "        jeans_path  = os.path.join(base_dir, \"data\", suite, \"jeans_deviation_total.csv\")\n",
    "        mass_path   = os.path.join(base_dir, \"data\", suite, \"halo_mass.csv\")\n",
    "\n",
    "        # load δJ_tot per halo\n",
    "        df_jeans = pd.read_csv(jeans_path)\n",
    "        jeans_dict = dict(zip(df_jeans[\"halo_id\"],\n",
    "                              pd.to_numeric(df_jeans[\"delta_J_tot\"], errors='coerce')))\n",
    "        # load M_vir per halo\n",
    "        df_mass = pd.read_csv(mass_path)\n",
    "        mass_dict = dict(zip(df_mass[\"halo_id\"],\n",
    "                             pd.to_numeric(df_mass[\"mvir\"], errors='coerce')))\n",
    "\n",
    "        # loop through each halo’s density file to compute η\n",
    "        for fname in sorted(os.listdir(density_dir)):\n",
    "            if not fname.endswith(\".csv\"):\n",
    "                continue\n",
    "            try:\n",
    "                halo_id = int(fname.split(\"_\")[1])\n",
    "                if halo_id not in jeans_dict or halo_id not in mass_dict:\n",
    "                    continue\n",
    "\n",
    "                # read profiles\n",
    "                df_rho = pd.read_csv(os.path.join(density_dir, fname))\n",
    "                df_vel = pd.read_csv(os.path.join(velocity_dir, fname))\n",
    "                df_menc= pd.read_csv(os.path.join(mass_dir, fname))\n",
    "\n",
    "                r      = pd.to_numeric(df_rho[\"r_scaled\"], errors='coerce').values\n",
    "                rho    = pd.to_numeric(df_rho[\"rho_scaled\"], errors='coerce').values\n",
    "                m_enc  = pd.to_numeric(df_menc[\"m_scaled\"], errors='coerce').values\n",
    "                sigma_tot = pd.to_numeric(df_vel[\"sigma_total_scaled\"], errors='coerce').values\n",
    "\n",
    "                # compute virial ratio η = 2K/|U|\n",
    "                eta = compute_eta_from_scaled_profiles(r, rho, m_enc, sigma_tot, r_max=1.0)\n",
    "                delta_J = jeans_dict[halo_id]\n",
    "                mvir    = mass_dict[halo_id]\n",
    "\n",
    "                if np.isfinite(eta) and np.isfinite(delta_J) and np.isfinite(mvir):\n",
    "                    eta_list.append(eta)\n",
    "                    delta_J_list.append(delta_J)\n",
    "                    mass_list.append(mvir)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] failed to process {suite} halo {fname}: {e}\")\n",
    "\n",
    "    # convert to arrays\n",
    "    delta_J_arr = np.array(delta_J_list)\n",
    "    eta_arr     = np.array(eta_list)\n",
    "    logM_arr    = np.log10(np.array(mass_list))\n",
    "\n",
    "    # check we have enough halos\n",
    "    if delta_J_arr.size < 5:\n",
    "        print(\"[Warning] Too few halos for meaningful correlation.\")\n",
    "        return\n",
    "\n",
    "    # 2) normalize δJ by median and std\n",
    "    med_J = np.median(delta_J_arr)\n",
    "    std_J = np.std(delta_J_arr)\n",
    "    if std_J <= 0:\n",
    "        print(\"[Warning] zero variance in Jeans deviation; cannot normalize.\")\n",
    "        return\n",
    "    delta_J_norm = (delta_J_arr - med_J) / std_J\n",
    "\n",
    "    # 3) compute Spearman correlation\n",
    "    rho_s, p_s = spearmanr(delta_J_norm, eta_arr)\n",
    "\n",
    "    # 4) plotting\n",
    "    plt.rcParams['text.usetex'] = True\n",
    "    plt.figure(figsize=(7,6), dpi=500)\n",
    "    sc = plt.scatter(\n",
    "        delta_J_norm, eta_arr,\n",
    "        c=logM_arr, cmap=\"viridis\", s=25, alpha=0.8, edgecolors=\"none\"\n",
    "    )\n",
    "    plt.axhline(1.0, color=\"gray\", linestyle=\"--\")\n",
    "    cbar = plt.colorbar(sc)\n",
    "    cbar.set_label(r\"$\\log_{10}(M_{\\rm vir}/M_\\odot)$\", fontsize=14)\n",
    "\n",
    "    plt.xlabel(r\"$\\delta_{J,\\mathrm{norm}} \\equiv (\\delta_J-\\delta_{J,\\mathrm{med}}) / \\sigma_{\\delta_J}$\", fontsize=18)\n",
    "    plt.ylabel(r\"$\\eta = \\frac{2K}{|U|}$\", fontsize=18)\n",
    "    plt.grid(True, linestyle=\":\")\n",
    "\n",
    "    txt = rf\"$\\rho = {rho_s:.3f}$\" + \"\\n\" + r\"$p < 10^{-10}$\"\n",
    "    plt.text(0.8, 0.15, txt,\n",
    "             transform=plt.gca().transAxes,\n",
    "             ha='center', va='bottom',\n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=1),\n",
    "             fontsize=15)\n",
    "    plt.savefig(os.path.join(base_dir, 'figure', f\"delta_jeans_vs_eta.pdf\"))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "compare_normalized_jeans_deviation_vs_virial_ratio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede3c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def const_model(r, a):\n",
    "    \"\"\"A one-parameter constant model: y(r) = a.\"\"\"\n",
    "    return a * np.ones_like(r)\n",
    "\n",
    "def sci_notation_latex(x, precision=2):\n",
    "\n",
    "    fmt = f\"{x:.{precision}e}\"\n",
    "    base, exponent = fmt.split(\"e\")\n",
    "    return rf\"{base} \\times 10^{{{int(exponent)}}}\"\n",
    "\n",
    "\n",
    "def plot_bestfit_ppsd_slope_vs_jeans_deviation_norm(base_dir, r_fit_range= (0.01, 1.0)): \n",
    "    slope_vals, jeans_norm_vals, log_mass_vals = [], [], []\n",
    "\n",
    "    for suite in suite_names:\n",
    "        slope_dir  = os.path.join(base_dir, \"data\", suite, \"ppsd_slope_profiles_r\")\n",
    "        jeans_path = os.path.join(base_dir, \"data\", suite, \"jeans_deviation_total.csv\")\n",
    "        mass_path  = os.path.join(base_dir, \"data\", suite, \"halo_mass.csv\")\n",
    "\n",
    "        df_jeans = pd.read_csv(jeans_path)\n",
    "        dJ       = pd.to_numeric(df_jeans[\"delta_J_tot\"], errors=\"coerce\")\n",
    "        median_j, std_j = np.nanmedian(dJ), np.nanstd(dJ)\n",
    "        jeans_norm = {hid: (dj - median_j) / std_j for hid, dj in zip(df_jeans[\"halo_id\"], dJ)}\n",
    "\n",
    "        df_mass  = pd.read_csv(mass_path)\n",
    "        mass_map = dict(zip(df_mass[\"halo_id\"], pd.to_numeric(df_mass[\"mvir\"], errors=\"coerce\")))\n",
    "\n",
    "        for fname in sorted(f for f in os.listdir(slope_dir) if f.endswith(\".csv\")):\n",
    "            try:\n",
    "                hid = int(fname.split(\"_\")[1]) \n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                df = pd.read_csv(os.path.join(slope_dir, fname))\n",
    "                r  = pd.to_numeric(df[\"r_scaled\"], errors=\"coerce\").to_numpy(float)\n",
    "                s  = pd.to_numeric(df[\"slope_Q_r\"], errors=\"coerce\").to_numpy(float)\n",
    "\n",
    "                mask = (r >= r_fit_range[0]) & (r <= r_fit_range[1]) & np.isfinite(s)\n",
    "                if mask.sum() < 5:\n",
    "                    continue  # not enough points for a stable fit\n",
    "\n",
    "                r_fit, s_fit = r[mask], s[mask]\n",
    "\n",
    "                try:\n",
    "                    popt, _ = curve_fit(const_model, r_fit, s_fit, p0=[np.median(s_fit)])\n",
    "                    best_slope = popt[0]\n",
    "                except Exception:\n",
    "                    best_slope = np.median(s_fit)\n",
    "\n",
    "                dj_norm = jeans_norm.get(hid, np.nan)\n",
    "                mvir    = mass_map.get(hid,  np.nan)\n",
    "\n",
    "                if np.isfinite(best_slope) and np.isfinite(dj_norm):\n",
    "                    slope_vals.append(best_slope)\n",
    "                    jeans_norm_vals.append(dj_norm)\n",
    "                    log_mass_vals.append(np.log10(mvir) if np.isfinite(mvir) else np.nan)\n",
    "\n",
    "            except Exception as err:\n",
    "                print(f\"[Warning] {suite}/{fname}: {err}\")\n",
    "\n",
    "    slope_vals, jeans_norm_vals, log_mass_vals = map(np.asarray, (slope_vals, jeans_norm_vals, log_mass_vals))\n",
    "\n",
    "    rho, pval = spearmanr(jeans_norm_vals, slope_vals)\n",
    "\n",
    "    plt.figure(figsize=(7, 6), dpi=500)\n",
    "    plt.rcParams['text.usetex'] = True\n",
    "    sc = plt.scatter(jeans_norm_vals, slope_vals, c=log_mass_vals,\n",
    "                     cmap=\"viridis\", s=20, alpha=0.8)\n",
    "    cbar = plt.colorbar(sc)\n",
    "    cbar.set_label(r\"$\\log_{10}(M_{\\rm vir}/M_\\odot)$\", fontsize=14)\n",
    "    plt.xlabel(r\"$\\delta_{J,\\mathrm{norm}} \\equiv (\\delta_J-\\delta_{J,\\mathrm{med}}) / \\sigma_{\\delta_J}$\", fontsize=18)\n",
    "    plt.ylabel(r\"$\\langle d\\log Q_r / d\\log r\\rangle$\", fontsize=18)\n",
    "    txt = rf\"$\\rho = {rho:.3f}$\" + \"\\n\" + rf\"$p = {sci_notation_latex(pval)}$\"\n",
    "    plt.gca().text(0.8, 0.85, txt, transform=plt.gca().transAxes,\n",
    "                   ha=\"center\", va=\"bottom\",\n",
    "                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8),fontsize=15)\n",
    "    plt.grid(True, linestyle=\":\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(base_dir,'figure', f\"ppsd_slope_vs_delta_jeans.pdf\"))\n",
    "    plt.show()\n",
    "\n",
    "suite_names = [\"SymphonyLMC\", \"SymphonyMilkyWay\", \"SymphonyGroup\", \"SymphonyLCluster\",'SymphonyCluster']\n",
    "plot_bestfit_ppsd_slope_vs_jeans_deviation_norm(base_dir='/Users/fengbocheng/Projects/Symphony-PPSD/output/z_0.5', r_fit_range=(1e-2, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4672ad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ppsd_slope_split_by_jeans_norm_quartiles_vs_r_per_suite(base_dir):\n",
    "\n",
    "    # Aggregators across all suites\n",
    "    jd_quart_slopes = {0: [], 1: [], 2: [], 3: []}\n",
    "    jd_quart_vals   = {0: [], 1: [], 2: [], 3: []}  # store per-halo jd_norm to report mean in label\n",
    "\n",
    "    r_ref = None\n",
    "    n_r_ref = None\n",
    "\n",
    "    for suite in suite_names:\n",
    "        dir_r = os.path.join(base_dir, \"data\", suite, \"ppsd_slope_profiles_r\")\n",
    "        if not os.path.isdir(dir_r):\n",
    "            continue\n",
    "\n",
    "        # Read per-halo total Jeans deviation for this suite\n",
    "        jd_path = os.path.join(base_dir, \"data\", suite, \"jeans_deviation_total.csv\")\n",
    "        if not os.path.isfile(jd_path):\n",
    "            continue\n",
    "\n",
    "        dfj = pd.read_csv(jd_path)\n",
    "        # Expect columns: \"halo_id\", \"delta_J_tot\"\n",
    "        dfj[\"halo_id_int\"] = pd.to_numeric(dfj.get(\"halo_id\"), errors=\"coerce\").astype(\"Int64\")\n",
    "        dfj[\"delta_J_tot\"] = pd.to_numeric(dfj.get(\"delta_J_tot\"), errors=\"coerce\")\n",
    "\n",
    "        vals = dfj[\"delta_J_tot\"].to_numpy(dtype=float)\n",
    "        vals = vals[np.isfinite(vals)]\n",
    "\n",
    "        # Suite-level normalization of total Jeans deviation: (x - median)/std\n",
    "        if vals.size < 4 or np.nanstd(vals) == 0:\n",
    "            jd_quart_edges = None\n",
    "        else:\n",
    "            med = np.nanmedian(vals)\n",
    "            std = np.nanstd(vals)\n",
    "            dfj[\"jd_norm\"] = (dfj[\"delta_J_tot\"] - med) / std\n",
    "            jd_quart_edges = np.nanpercentile(dfj[\"jd_norm\"], [25, 50, 75])\n",
    "\n",
    "        # Build lookup map: halo_id -> jd_norm\n",
    "        jd_norm_map = {}\n",
    "        if jd_quart_edges is not None and \"jd_norm\" in dfj.columns:\n",
    "            for hid, jn in zip(dfj[\"halo_id_int\"], dfj[\"jd_norm\"]):\n",
    "                if pd.notna(hid) and np.isfinite(jn):\n",
    "                    jd_norm_map[int(hid)] = float(jn)\n",
    "\n",
    "        # Helper: assign quartile index\n",
    "        def assign_quartile(val, edges):\n",
    "            q1, q2, q3 = edges\n",
    "            if val <= q1:\n",
    "                return 0\n",
    "            elif val <= q2:\n",
    "                return 1\n",
    "            elif val <= q3:\n",
    "                return 2\n",
    "            else:\n",
    "                return 3\n",
    "\n",
    "        # Iterate slope curves for this suite\n",
    "        for fn in sorted(os.listdir(dir_r)):\n",
    "            if not fn.endswith(\".csv\"):\n",
    "                continue\n",
    "            try:\n",
    "                # parse halo index from filename like \"halo_012_profile.csv\"\n",
    "                idx = int(fn.split(\"_\")[1])\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            if (jd_quart_edges is None) or (idx not in jd_norm_map):\n",
    "                continue\n",
    "\n",
    "            df = pd.read_csv(os.path.join(dir_r, fn))\n",
    "            sr = pd.to_numeric(df[\"slope_Q_r\"], errors=\"coerce\").to_numpy()\n",
    "\n",
    "            if r_ref is None:\n",
    "                r_ref = pd.to_numeric(df[\"r_scaled\"], errors=\"coerce\").to_numpy()\n",
    "                n_r_ref = r_ref.size\n",
    "            else:\n",
    "                # Skip curves with mismatched radial grid length\n",
    "                if sr.size != n_r_ref:\n",
    "                    continue\n",
    "\n",
    "            jn = jd_norm_map[idx]\n",
    "            q_idx = assign_quartile(jn, jd_quart_edges)\n",
    "            jd_quart_slopes[q_idx].append(sr)\n",
    "            jd_quart_vals[q_idx].append(jn)\n",
    "\n",
    "    if r_ref is None:\n",
    "        print(\"[Warning] No valid slope data found for Jeans-deviation quartiles.\")\n",
    "        return\n",
    "\n",
    "    # ---- Plot Q1 & Q4 only----\n",
    "    plt.rcParams[\"text.usetex\"] = True\n",
    "    fig, ax = plt.subplots(figsize=(7, 5), dpi=600)\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.grid(which=\"both\", linestyle=\":\")\n",
    "    ax.axhline(-1.875, ls=\"--\", color=\"black\", lw=1, label=r\"$\\frac{d\\log Q_r}{d\\log r}=-1.875$\")\n",
    "    ax.set_xlim(6e-3, 1.1)\n",
    "    ax.set_ylim(-2.3, -1.2)\n",
    "    ax.set_xlabel(r\"$r / R_{\\rm vir}$\", fontsize=16)\n",
    "    ax.set_ylabel(r\"$d\\log Q_r / d\\log r$\", fontsize=16)\n",
    "    ax.tick_params(axis=\"both\", labelsize=12)\n",
    "\n",
    "    cmap = plt.cm.Reds\n",
    "    labels = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
    "    colors = [cmap(0.3), cmap(0.5), cmap(0.7), cmap(0.9)]  \n",
    "\n",
    "    for i, q in enumerate([0, 1, 2, 3]):  \n",
    "        Ys = jd_quart_slopes[q]\n",
    "        vs = jd_quart_vals[q]\n",
    "        if len(Ys) == 0:\n",
    "            ax.plot([], [], label=f\"{labels[i]} (N=0)\")\n",
    "            continue\n",
    "\n",
    "        Y = np.vstack(Ys)\n",
    "        mu = np.nanmean(Y, axis=0)\n",
    "        sd = np.nanstd(Y, axis=0)\n",
    "        vmean = float(np.nanmean(vs)) if len(vs) else np.nan\n",
    "\n",
    "        #ax.fill_between(r_ref, mu - sd, mu + sd, alpha=0.25, color=colors[i])\n",
    "        ax.plot(\n",
    "            r_ref, mu, lw=1.6, color=colors[i],\n",
    "            label=r\"$\" + labels[i] + \n",
    "                r\":\\ \\langle \\delta_{J,\\mathrm{norm}} \\rangle = $\" + rf\"${vmean:.2f}$\"\n",
    "        )\n",
    "\n",
    "    ax.legend(loc=\"upper left\", fontsize=11)\n",
    "    plt.tight_layout()\n",
    "    out_path = os.path.join(base_dir, 'figure', \"ppsd_slope_r_split_jeans_norm_quartiles.pdf\")\n",
    "    plt.savefig(out_path)\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "plot_ppsd_slope_split_by_jeans_norm_quartiles_vs_r_per_suite(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1181f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantify_jeans_vs_cgamma(x_var=\"cvir\"):\n",
    "    x_vals, delta_j_vals, mass_vals = [], [], []\n",
    "\n",
    "    for suite in suite_names:\n",
    "        cvir_path = os.path.join(base_dir, \"data\", suite, \"halo_concentrations.csv\")\n",
    "        gamma_path = os.path.join(base_dir, \"data\", suite, \"accretion_rates.csv\")\n",
    "        mass_path = os.path.join(base_dir, \"data\", suite, \"halo_mass.csv\")\n",
    "        jeans_path = os.path.join(base_dir, \"data\", suite, \"jeans_deviation_total.csv\")\n",
    "\n",
    "        df_cvir = pd.read_csv(cvir_path)\n",
    "        df_gamma = pd.read_csv(gamma_path)\n",
    "        df_mass = pd.read_csv(mass_path)\n",
    "        df_jeans = pd.read_csv(jeans_path)\n",
    "\n",
    "        # Create lookup dictionaries\n",
    "        cvir_dict = dict(zip(df_cvir[\"halo_id\"], pd.to_numeric(df_cvir[\"cvir\"], errors='coerce')))\n",
    "        gamma_dict = dict(zip(df_gamma[\"halo_index\"], pd.to_numeric(df_gamma[\"gamma\"], errors='coerce')))\n",
    "        mass_dict = dict(zip(df_mass[\"halo_id\"], pd.to_numeric(df_mass[\"mvir\"], errors='coerce')))\n",
    "        delta_j_dict = dict(zip(df_jeans[\"halo_id\"], pd.to_numeric(df_jeans[\"delta_J_tot\"], errors='coerce')))\n",
    "\n",
    "        # Normalized variables (computed within each suite)\n",
    "        if x_var == \"delta_c_norm\":\n",
    "            c_vals = df_cvir[\"cvir\"].values\n",
    "            c_med, c_std = np.nanmedian(c_vals), np.nanstd(c_vals)\n",
    "            x_dict = {row[\"halo_id\"]: (row[\"cvir\"] - c_med) / c_std for _, row in df_cvir.iterrows()}\n",
    "\n",
    "        elif x_var == \"delta_gamma_norm\":\n",
    "            vals = df_gamma[\"gamma\"].values\n",
    "            valid_mask = (vals > 0) & np.isfinite(vals)\n",
    "            log_vals = np.log10(vals[valid_mask])\n",
    "            g_med, g_std = np.nanmedian(log_vals), np.nanstd(log_vals)\n",
    "            x_dict = {\n",
    "                row[\"halo_index\"]: (np.log10(row[\"gamma\"]) - g_med) / g_std\n",
    "                for _, row in df_gamma.iterrows()\n",
    "                if row[\"gamma\"] > 0 and np.isfinite(row[\"gamma\"])\n",
    "            }\n",
    "\n",
    "        # Loop over halos\n",
    "        for halo_id in delta_j_dict:\n",
    "            delta_j = delta_j_dict.get(halo_id)\n",
    "            mass = mass_dict.get(halo_id, np.nan)\n",
    "\n",
    "            if x_var == \"cvir\":\n",
    "                x = cvir_dict.get(halo_id)\n",
    "            elif x_var == \"gamma\":\n",
    "                x = gamma_dict.get(halo_id)\n",
    "                x = np.log10(x) if x is not None and x > 0 else np.nan\n",
    "            elif x_var in [\"delta_c_norm\", \"delta_gamma_norm\"]:\n",
    "                x = x_dict.get(halo_id)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            x = pd.to_numeric(x, errors='coerce')\n",
    "            delta_j = pd.to_numeric(delta_j, errors='coerce')\n",
    "            if np.isfinite(x) and np.isfinite(delta_j):\n",
    "                x_vals.append(x)\n",
    "                delta_j_vals.append(delta_j)\n",
    "                mass_vals.append(mass)\n",
    "\n",
    "    x_vals = np.array(x_vals)\n",
    "    delta_j_vals = np.array(delta_j_vals)\n",
    "    mass_vals = np.array(mass_vals)\n",
    "\n",
    "    if len(x_vals) < 2:\n",
    "        print(\"[Warning] Not enough valid data.\")\n",
    "        return\n",
    "\n",
    "    log_mass = np.log10(mass_vals)\n",
    "    spearman_r, spearman_p = spearmanr(x_vals, delta_j_vals)\n",
    "\n",
    "    plt.figure(figsize=(7, 6), dpi=600)\n",
    "    plt.rcParams['text.usetex'] = True\n",
    "    sc = plt.scatter(x_vals, delta_j_vals, c=log_mass, cmap=\"viridis\", s=20, alpha=0.8)\n",
    "    cbar = plt.colorbar(sc)\n",
    "    cbar.set_label(r\"$\\log_{10}(M_{\\rm vir}/M_\\odot)$\", fontsize=14)\n",
    "    plt.grid(True, linestyle=\":\")\n",
    "    plt.xlabel({\n",
    "        \"cvir\": r\"$c$\",\n",
    "        \"gamma\": r\"$\\log_{10}(\\Gamma)$\",\n",
    "        \"delta_c_norm\": r\"$\\Delta c/\\sigma_c$\",\n",
    "        \"delta_gamma_norm\": r\"$\\Delta \\log \\Gamma/\\sigma_{\\log \\Gamma}$\"\n",
    "    }.get(x_var, x_var), fontsize=18)\n",
    "    plt.ylabel(r\"$\\delta_J$\", fontsize=18)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    txt = rf\"$\\rho = {spearman_r:.3f}$\" + \"\\n\" + rf\"$p = {sci_notation_latex(spearman_p)}$\"\n",
    "    plt.gca().text(0.8, 0.85, txt, transform=plt.gca().transAxes,\n",
    "                   ha=\"center\", va=\"bottom\",\n",
    "                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8),fontsize=13)\n",
    "    plt.savefig(os.path.join(base_dir,'figure', f\"delta_jeans_vs_{x_var}.pdf\"))\n",
    "    plt.show()\n",
    "\n",
    "quantify_jeans_vs_cgamma(x_var=\"delta_c_norm\")\n",
    "quantify_jeans_vs_cgamma(x_var=\"delta_gamma_norm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Astronomy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
