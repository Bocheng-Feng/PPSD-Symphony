{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc368a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy.constants import G\n",
    "from astropy import units as u\n",
    "from scipy.integrate import quad\n",
    "import symlib\n",
    "import os\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.optimize import curve_fit   \n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "base_dir='/Users/fengbocheng/Projects/Symphony-PPSD/output/z_0'\n",
    "suite_names = [\"SymphonyLMC\", \"SymphonyMilkyWay\", \"SymphonyGroup\", \"SymphonyLCluster\", \"SymphonyCluster\"]\n",
    "sim_colors = {\n",
    "        \"SymphonyLMC\": sns.color_palette(\"colorblind\")[4],\n",
    "        \"SymphonyMilkyWay\": sns.color_palette(\"colorblind\")[0],\n",
    "        \"SymphonyGroup\": sns.color_palette(\"colorblind\")[2],\n",
    "        \"SymphonyLCluster\": sns.color_palette(\"colorblind\")[1],\n",
    "        \"SymphonyCluster\": sns.color_palette(\"colorblind\")[3],\n",
    "    }\n",
    "sim_names = {\n",
    "        \"SymphonyLMC\": \"LMC\",\n",
    "        \"SymphonyMilkyWay\": \"Milky~Way\",\n",
    "        \"SymphonyGroup\": \"Group\",\n",
    "        \"SymphonyLCluster\": \"L-Cluster\",\n",
    "        \"SymphonyCluster\": \"Cluster\",\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ad4521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantify_correlation(base_dir, suite_names, r_target=0.01, x_var=\"cvir\", slope_var=\"slope_Q_r\"):\n",
    "    \"\"\" \n",
    "    Quantify the correlation between PPSD slope and halo properties: concentration or accretion rate at target radius.\n",
    "    \"\"\"\n",
    "    slope_vals, x_vals, mass_vals = [], [], []\n",
    "\n",
    "    for suite in suite_names:\n",
    "        slope_r_dir = os.path.join(base_dir, \"data\", suite, \"ppsd_slope_profiles_r\")\n",
    "        cvir_path = os.path.join(base_dir, \"data\", suite, \"halo_concentrations.csv\")\n",
    "        gamma_path = os.path.join(base_dir, \"data\", suite, \"accretion_rates.csv\")\n",
    "        mass_path = os.path.join(base_dir, \"data\", suite, \"halo_mass.csv\")\n",
    "\n",
    "        df_cvir = pd.read_csv(cvir_path)\n",
    "        df_gamma = pd.read_csv(gamma_path)\n",
    "        cvir_dict = dict(zip(df_cvir[\"halo_id\"], df_cvir[\"cvir\"]))\n",
    "        gamma_dict = dict(zip(df_gamma[\"halo_id\"], df_gamma[\"gamma\"]))\n",
    "        mass_dict = dict(zip(pd.read_csv(mass_path)[\"halo_id\"], pd.read_csv(mass_path)[\"mvir\"]))\n",
    "\n",
    "        if x_var == \"delta_c_norm\":\n",
    "            c_vals = df_cvir[\"cvir\"].values\n",
    "            c_med = np.nanmedian(c_vals)\n",
    "            c_std = np.nanstd(c_vals)\n",
    "            delta_c_dict = {row[\"halo_id\"]: (row[\"cvir\"] - c_med) / c_std for _, row in df_cvir.iterrows()}\n",
    "\n",
    "        elif x_var == \"delta_gamma_norm\":\n",
    "            valid_gamma = df_gamma[\"gamma\"].values\n",
    "            valid_mask = (valid_gamma > 0) & np.isfinite(valid_gamma)\n",
    "            log_g_vals = np.log10(valid_gamma[valid_mask])\n",
    "\n",
    "            log_g_med = np.nanmedian(log_g_vals)\n",
    "            log_g_std = np.nanstd(log_g_vals)\n",
    "\n",
    "            delta_g_dict = {\n",
    "                row[\"halo_id\"]: (np.log10(row[\"gamma\"]) - log_g_med) / log_g_std\n",
    "                for _, row in df_gamma.iterrows()\n",
    "                if row[\"gamma\"] > 0 and np.isfinite(row[\"gamma\"])\n",
    "            }\n",
    "\n",
    "        for f in sorted([f for f in os.listdir(slope_r_dir) if f.endswith(\".csv\")]):\n",
    "            try:\n",
    "                halo_id = int(f.split(\"_\")[1])\n",
    "                df = pd.read_csv(os.path.join(slope_r_dir, f))\n",
    "                r = df[\"r_scaled\"].values\n",
    "                slope = df[slope_var].values\n",
    "                interp_func = interp1d(r, slope, bounds_error=False, fill_value=np.nan)\n",
    "                slope_val = float(interp_func(r_target))\n",
    "\n",
    "                if x_var == \"cvir\":\n",
    "                    x = cvir_dict.get(halo_id)\n",
    "                elif x_var == \"gamma\":\n",
    "                    x = gamma_dict.get(halo_id)\n",
    "                elif x_var == \"delta_c_norm\":\n",
    "                    x = delta_c_dict.get(halo_id)\n",
    "                elif x_var == \"delta_gamma_norm\":\n",
    "                    x = delta_g_dict.get(halo_id)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported x_var: {x_var}\")\n",
    "\n",
    "                mass = mass_dict.get(halo_id, np.nan)\n",
    "                try:\n",
    "                    slope_val = float(interp_func(r_target))\n",
    "                    x = float(x) \n",
    "                    mass = float(mass)\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "                if np.isfinite(slope_val) and np.isfinite(x) and (x_var != \"gamma\" or x > 0):\n",
    "                    slope_vals.append(slope_val)\n",
    "                    x_vals.append(x)\n",
    "                    mass_vals.append(mass)\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Failed to process {f} in {suite}: {e}\")\n",
    "                continue\n",
    "\n",
    "    slope_vals = np.array(slope_vals)\n",
    "    x_vals = np.array(x_vals)\n",
    "    mass_vals = np.array(mass_vals)\n",
    "\n",
    "    if len(slope_vals) < 2:\n",
    "        print(\"[Warning] Not enough valid data to compute correlation.\")\n",
    "        return\n",
    "\n",
    "    log_mass = np.log10(mass_vals)\n",
    "    log_x = np.log10(x_vals) if x_var == \"gamma\" else x_vals\n",
    "\n",
    "    spearman_r, spearman_p = spearmanr(log_x, slope_vals)\n",
    "\n",
    "    plt.figure(figsize=(7, 6), dpi=500)\n",
    "    scatter = plt.scatter(log_x, slope_vals, c=log_mass, cmap=\"viridis\", s=20, alpha=0.8, edgecolors='none')\n",
    "    cbar = plt.colorbar(scatter, label=r\"$\\log_{10}(M_{\\rm vir} / M_\\odot)$\")\n",
    "\n",
    "    xlabel_map = {\n",
    "        \"cvir\": r\"$c_{\\rm vir}$\",\n",
    "        \"gamma\": r\"$\\log_{10}(\\gamma)$\",\n",
    "        \"delta_c_norm\": r\"$(c - \\tilde{c}) / \\sigma_c$\",\n",
    "        \"delta_gamma_norm\": r\"$(\\gamma - \\tilde{\\gamma}) / \\sigma_\\gamma$\"\n",
    "    }\n",
    "    plt.xlabel(xlabel_map.get(x_var, x_var))\n",
    "    plt.ylabel(fr\"{slope_var} at $r = {r_target:.3f} R_{{\\rm vir}}$\")\n",
    "    plt.title(f\"Correlation at $r = {r_target} R_{{\\\\rm vir}}$\")\n",
    "    plt.grid(True, linestyle=\":\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    textstr = '\\n'.join((\n",
    "        rf\"Spearman $\\rho$ = {spearman_r:.3f}\",\n",
    "        rf\"$p$ = {spearman_p:.2e}\"\n",
    "    ))\n",
    "    plt.text(0.97, 0.03, textstr,\n",
    "             transform=plt.gca().transAxes,\n",
    "             fontsize=10, va='bottom', ha='right',\n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", edgecolor=\"gray\", alpha=0.8))\n",
    "\n",
    "    print(f\"Spearman ρ = {spearman_r:.3f}, p = {spearman_p:.2e}\")\n",
    "    plt.show()\n",
    "    \n",
    "base_dir = \"/Users/fengbocheng/Projects/Symphony-PPSD\"\n",
    "suite_names = [\"SymphonyLMC\", \"SymphonyMilkyWay\", \"SymphonyGroup\", \"SymphonyLCluster\", \"SymphonyCluster\"]\n",
    "quantify_correlation(\n",
    "    base_dir, suite_names,\n",
    "    r_target=1,\n",
    "    x_var=\"delta_gamma_norm\",\n",
    "    slope_var=\"slope_Q_r\"\n",
    ")\n",
    "\n",
    "quantify_correlation(\n",
    "    base_dir, suite_names,\n",
    "    r_target=1,\n",
    "    x_var=\"delta_c_norm\",\n",
    "    slope_var=\"slope_Q_r\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97563ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def const_model(r, a):\n",
    "    \"\"\"Constant model for curve_fit.\"\"\"\n",
    "    return a * np.ones_like(r)\n",
    "\n",
    "def sci_notation_latex(x, precision=2):\n",
    "    \"\"\"\n",
    "    Return a string like 1.23e-4 → 1.23 \\\\times 10^{-4}\n",
    "    \"\"\"\n",
    "    fmt = f\"{x:.{precision}e}\"\n",
    "    base, exponent = fmt.split(\"e\")\n",
    "    return rf\"{base} \\times 10^{{{int(exponent)}}}\"\n",
    "\n",
    "def best_slope_vs_cgamma(base_dir, suite_names,\n",
    "                          x_var=\"cvir\",\n",
    "                          slope_column=\"slope_Q_r\",\n",
    "                          fit_range=(0.01, 1.0)):\n",
    "\n",
    "    slope_vals, slope_errs, x_vals, mass_vals = [], [], [], []\n",
    "\n",
    "    for suite in suite_names:\n",
    "        slope_dir = os.path.join(base_dir, \"data\", suite, \"ppsd_slope_profiles_r\")\n",
    "\n",
    "        df_cvir  = pd.read_csv(os.path.join(base_dir, \"data\", suite, \"halo_concentrations.csv\"))\n",
    "        df_gamma = pd.read_csv(os.path.join(base_dir, \"data\", suite, \"accretion_rates.csv\"))\n",
    "        df_mass  = pd.read_csv(os.path.join(base_dir, \"data\", suite, \"halo_mass.csv\"))\n",
    "\n",
    "        cvir_dict  = dict(zip(df_cvir[\"halo_id\"], pd.to_numeric(df_cvir[\"cvir\"], errors='coerce')))\n",
    "        mass_dict  = dict(zip(df_mass[\"halo_id\"], pd.to_numeric(df_mass[\"mvir\"], errors='coerce')))\n",
    "        # Raw, coerced gamma series\n",
    "        g_series = pd.to_numeric(df_gamma[\"gamma\"], errors='coerce')\n",
    "        mask_g   = np.isfinite(g_series) & (g_series > 0)\n",
    "\n",
    "        # Filtered dict: halo_id -> gamma (>0)\n",
    "        gamma_dict = dict(zip(df_gamma.loc[mask_g, \"halo_id\"], g_series.loc[mask_g]))\n",
    "\n",
    "        if x_var == \"delta_c_norm\":\n",
    "            cm, cstd = df_cvir[\"cvir\"].median(), df_cvir[\"cvir\"].std()\n",
    "            delta_c_dict = {hid: (c - cm) / cstd\n",
    "                            for hid, c in zip(df_cvir[\"halo_id\"], df_cvir[\"cvir\"])}\n",
    "\n",
    "        if x_var == \"delta_gamma_norm\":\n",
    "            g_series = pd.to_numeric(df_gamma[\"gamma\"], errors='coerce')\n",
    "            mask_g   = np.isfinite(g_series) & (g_series > 0)\n",
    "            lg       = np.log10(g_series.loc[mask_g].to_numpy())\n",
    "            if lg.size >= 2 and np.nanstd(lg) > 0:\n",
    "                gm, gstd = np.nanmedian(lg), np.nanstd(lg)\n",
    "                delta_g_dict = {\n",
    "                    idx: (np.log10(val) - gm) / gstd\n",
    "                    for idx, val in zip(df_gamma.loc[mask_g, \"halo_id\"], g_series.loc[mask_g])\n",
    "                }\n",
    "            else:\n",
    "                delta_g_dict = {}\n",
    "        for fname in sorted(f for f in os.listdir(slope_dir) if f.endswith(\".csv\")):\n",
    "            try:\n",
    "                hid = int(fname.split(\"_\")[1])\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                df = pd.read_csv(os.path.join(slope_dir, fname))\n",
    "                r  = df[\"r_scaled\"].to_numpy(dtype=float)\n",
    "                sQ = pd.to_numeric(df[slope_column], errors='coerce').to_numpy(dtype=float)\n",
    "                mask = (r >= fit_range[0]) & (r <= fit_range[1]) & np.isfinite(sQ)\n",
    "                if mask.sum() < 3:\n",
    "                    continue\n",
    "\n",
    "                popt, pcov = curve_fit(const_model, r[mask], sQ[mask],\n",
    "                                       p0=np.mean(sQ[mask]),\n",
    "                                       maxfev=10000)\n",
    "                slope_fit = popt[0]\n",
    "                slope_err = np.sqrt(np.diag(pcov))[0] if pcov.size else np.nan\n",
    "\n",
    "                if   x_var == \"cvir\":             x = cvir_dict.get(hid,  np.nan)\n",
    "                elif x_var == \"gamma\":            x = gamma_dict.get(hid, np.nan)\n",
    "                elif x_var == \"delta_c_norm\":     x = delta_c_dict.get(hid, np.nan)\n",
    "                elif x_var == \"delta_gamma_norm\": x = delta_g_dict.get(hid, np.nan)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unsupported x_var: {x_var}\")\n",
    "\n",
    "                mass = mass_dict.get(hid, np.nan)\n",
    "\n",
    "                if np.isfinite(slope_fit) and np.isfinite(x):\n",
    "                    slope_vals.append(slope_fit)\n",
    "                    slope_errs.append(slope_err)\n",
    "                    x_vals.append(x)\n",
    "                    mass_vals.append(mass)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] {suite}/{fname}: {e}\")\n",
    "\n",
    "    slope_vals = np.asarray(slope_vals)\n",
    "    x_vals     = np.asarray(x_vals)\n",
    "    mass_vals  = np.asarray(mass_vals)\n",
    "\n",
    "    log_mass = np.log10(mass_vals)\n",
    "    log_x    = np.log10(x_vals) if x_var == \"gamma\" else x_vals\n",
    "\n",
    "    rho, pval = spearmanr(log_x, slope_vals)\n",
    "\n",
    "    plt.figure(figsize=(6, 5), dpi=500)\n",
    "    plt.rcParams['text.usetex'] = True\n",
    "\n",
    "    cmap = plt.cm.Oranges  \n",
    "    colors = [cmap(0.3), cmap(0.5), cmap(0.7), cmap(0.9)]\n",
    "    q1, q2, q3 = np.nanpercentile(log_x, [25, 50, 75])\n",
    "    edges = [(-np.inf, q1), (q1, q2), (q2, q3), (q3, np.inf)]\n",
    "    ax = plt.gca()\n",
    "\n",
    "    x_min, x_max = np.nanmin(log_x), np.nanmax(log_x)\n",
    "    pad = 0.02 * (x_max - x_min) if np.isfinite(x_max - x_min) else 0.0\n",
    "    ax.set_xlim(x_min - pad, x_max + pad)\n",
    "    x0, x1 = ax.get_xlim()\n",
    "\n",
    "    q1, q2, q3 = np.nanpercentile(log_x, [25, 50, 75])\n",
    "    edges = [(q1, q1), (q1, q2), (q2, q3), (q3, q3)] \n",
    "\n",
    "    for i, (lo, hi) in enumerate(edges):\n",
    "        if i == 0:   # Q1\n",
    "            lo = x0\n",
    "            hi = q1\n",
    "        elif i == 1: # Q2\n",
    "            lo = q1\n",
    "            hi = q2\n",
    "        elif i == 2: # Q3\n",
    "            lo = q2\n",
    "            hi = q3\n",
    "        else:        # Q4\n",
    "            lo = q3\n",
    "            hi = x1\n",
    "        #ax.axvspan(lo, hi, color=colors[i], alpha=0.4, zorder=0)\n",
    "        \n",
    "    sc = plt.scatter(log_x, slope_vals, c=log_mass, cmap=\"viridis\", s=20, alpha=1)\n",
    "    cbar = plt.colorbar(sc)\n",
    "    cbar.set_label(r\"$\\log_{10}(M_{\\rm vir}/M_\\odot)$\", fontsize=14)\n",
    "    if x_var == \"delta_c_norm\":\n",
    "        plt.xlabel(r\"$c_{\\mathrm{norm}} \\equiv \\frac{c-c_{\\mathrm{med}}}{\\sigma_c}$\", fontsize=15)\n",
    "    if x_var == \"delta_gamma_norm\":\n",
    "        plt.xlabel(r\"$\\Gamma_{\\mathrm{norm}} \\equiv \\frac{\\Gamma-\\Gamma_{\\mathrm{med}}}{\\sigma_\\Gamma}$\", fontsize=15)\n",
    "    if x_var == \"cvir\":\n",
    "        plt.xlabel(r\"$c$\", fontsize=15)\n",
    "    if x_var == \"gamma\":\n",
    "        plt.xlabel(r\"$\\Gamma \\equiv \\log_{10} \\frac{\\Delta M_{\\mathrm{host}}(t_\\mathrm{dyn})}{t_\\mathrm{dyn}}$\", fontsize=15)\n",
    "\n",
    "    plt.ylabel(r\"$\\langle d\\log Q_r / d\\log r\\rangle$\", fontsize=15)\n",
    "    txt = rf\"$\\rho = {rho:.3f}$\" + \"\\n\" + rf\"$p = {sci_notation_latex(pval)}$\"\n",
    "    plt.gca().text(\n",
    "        0.8, 0.1, txt, transform=plt.gca().transAxes,\n",
    "        ha=\"center\", va=\"bottom\",\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.6), fontsize=13\n",
    "    )\n",
    "    plt.grid(True, linestyle=\":\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    ax.axhline(-1.875, ls=\"--\", color=\"black\", lw=1)\n",
    "    plt.savefig(os.path.join(base_dir, 'figure', f\"ppsd_slope_vs_{x_var}.pdf\"))\n",
    "    plt.show()\n",
    "\n",
    "best_slope_vs_cgamma(base_dir, suite_names,\n",
    "                     x_var=\"delta_c_norm\",\n",
    "                     slope_column=\"slope_Q_r\",\n",
    "                     fit_range=(6e-3,1.1))\n",
    "\n",
    "best_slope_vs_cgamma(base_dir, suite_names = [\"SymphonyLMC\", \"SymphonyMilkyWay\", \"SymphonyGroup\", \"SymphonyLCluster\"],\n",
    "                     x_var=\"delta_gamma_norm\",\n",
    "                     slope_column=\"slope_Q_r\",\n",
    "                     fit_range=(6e-3, 1.1))\n",
    "best_slope_vs_cgamma(base_dir, suite_names,\n",
    "                     x_var=\"cvir\",\n",
    "                     slope_column=\"slope_Q_r\",\n",
    "                     fit_range=(6e-3,1.1))\n",
    "\n",
    "best_slope_vs_cgamma(base_dir, suite_names = [\"SymphonyLMC\", \"SymphonyMilkyWay\", \"SymphonyGroup\", \"SymphonyLCluster\"],\n",
    "                     x_var=\"gamma\",\n",
    "                     slope_column=\"slope_Q_r\",\n",
    "                     fit_range=(6e-3, 1.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7dbe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ppsd_slope_split_by_quartiles_norm_vs_r_per_suite():\n",
    "\n",
    "    # For c_norm\n",
    "    c_quart_slopes = {0: [], 1: [], 2: [], 3: []}\n",
    "    c_quart_vals   = {0: [], 1: [], 2: [], 3: []}  # store per-halo c_norm to report mean in label\n",
    "\n",
    "    # For gamma_norm\n",
    "    g_quart_slopes = {0: [], 1: [], 2: [], 3: []}\n",
    "    g_quart_vals   = {0: [], 1: [], 2: [], 3: []}  # store per-halo gamma_norm to report mean in label\n",
    "\n",
    "    r_ref = None\n",
    "    n_r_ref = None\n",
    "\n",
    "    # -------------------------\n",
    "    # Loop over suites\n",
    "    # -------------------------\n",
    "    for suite in suite_names:\n",
    "        dir_r = os.path.join(base_dir, \"data\", suite, \"ppsd_slope_profiles_r\")\n",
    "        if not os.path.isdir(dir_r):\n",
    "            continue\n",
    "\n",
    "        # --- read c and gamma tables (suite-scope statistics) ---\n",
    "        c_path = os.path.join(base_dir, \"data\", suite, \"halo_concentrations.csv\")\n",
    "        g_path = os.path.join(base_dir, \"data\", suite, \"accretion_rates.csv\")\n",
    "        if not os.path.isfile(c_path):\n",
    "            continue\n",
    "\n",
    "        dfc = pd.read_csv(c_path)\n",
    "        dfc[\"halo_id_int\"] = pd.to_numeric(dfc[\"halo_id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "        dfc[\"cvir\"] = pd.to_numeric(dfc[\"cvir\"], errors=\"coerce\")\n",
    "\n",
    "        # Concentration suite-level normalization\n",
    "        c_valid = dfc[\"cvir\"].to_numpy(dtype=float)\n",
    "        c_valid = c_valid[np.isfinite(c_valid)]\n",
    "        if c_valid.size < 4 or np.nanstd(c_valid) == 0:\n",
    "            # not enough spread or too few to quartile\n",
    "            c_quart_edges = None\n",
    "        else:\n",
    "            c_med = np.nanmedian(c_valid)\n",
    "            c_std = np.nanstd(c_valid)\n",
    "            dfc[\"c_norm\"] = (dfc[\"cvir\"] - c_med) / c_std\n",
    "            c_quart_edges = np.nanpercentile(dfc[\"c_norm\"], [25, 50, 75])\n",
    "\n",
    "        # Gamma table may be missing or sparse\n",
    "        if os.path.isfile(g_path):\n",
    "            dfg = pd.read_csv(g_path)\n",
    "            dfg[\"halo_id_int\"] = pd.to_numeric(dfg[\"halo_id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "            dfg[\"gamma\"] = pd.to_numeric(dfg[\"gamma\"], errors=\"coerce\")\n",
    "            # Suite-level gamma normalization (log10, gamma>0)\n",
    "            mask_pos = (dfg[\"gamma\"] > 0) & dfg[\"gamma\"].notna()\n",
    "            if mask_pos.sum() >= 4:\n",
    "                lg = np.log10(dfg.loc[mask_pos, \"gamma\"].to_numpy(dtype=float))\n",
    "                gm = np.nanmedian(lg)\n",
    "                gs = np.nanstd(lg)\n",
    "                if np.isfinite(gs) and gs > 0:\n",
    "                    dfg.loc[mask_pos, \"g_norm\"] = (np.log10(dfg.loc[mask_pos, \"gamma\"]) - gm) / gs\n",
    "                    g_quart_edges = np.nanpercentile(dfg.loc[mask_pos, \"g_norm\"], [25, 50, 75])\n",
    "                else:\n",
    "                    g_quart_edges = None\n",
    "            else:\n",
    "                g_quart_edges = None\n",
    "        else:\n",
    "            dfg = None\n",
    "            g_quart_edges = None\n",
    "\n",
    "        # Build quick lookup for this suite\n",
    "        c_norm_map = {}\n",
    "        if c_quart_edges is not None:\n",
    "            for hid, c_norm in zip(dfc[\"halo_id_int\"], dfc[\"c_norm\"]):\n",
    "                if pd.notna(hid) and np.isfinite(c_norm):\n",
    "                    c_norm_map[int(hid)] = float(c_norm)\n",
    "\n",
    "        g_norm_map = {}\n",
    "        if dfg is not None and g_quart_edges is not None and \"g_norm\" in dfg.columns:\n",
    "            for hid, g_norm in zip(dfg[\"halo_id_int\"], dfg[\"g_norm\"]):\n",
    "                if pd.notna(hid) and np.isfinite(g_norm):\n",
    "                    g_norm_map[int(hid)] = float(g_norm)\n",
    "\n",
    "        # Helper: assign quartile index given edges\n",
    "        def assign_quartile(val, edges):\n",
    "            # edges: [q25, q50, q75]\n",
    "            q1, q2, q3 = edges\n",
    "            if val <= q1:\n",
    "                return 0\n",
    "            elif val <= q2:\n",
    "                return 1\n",
    "            elif val <= q3:\n",
    "                return 2\n",
    "            else:\n",
    "                return 3\n",
    "\n",
    "        # --- iterate halos in this suite, read slope curves, and assign to quartiles ---\n",
    "        for fn in sorted(os.listdir(dir_r)):\n",
    "            if not fn.endswith(\".csv\"):\n",
    "                continue\n",
    "            # parse halo index from filename like \"halo_012_profile.csv\"\n",
    "            try:\n",
    "                idx = int(fn.split(\"_\")[1])\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            full_path = os.path.join(dir_r, fn)\n",
    "            df = pd.read_csv(full_path)\n",
    "            sr = pd.to_numeric(df[\"slope_Q_r\"], errors=\"coerce\").to_numpy()\n",
    "            if r_ref is None:\n",
    "                r_ref = df[\"r_scaled\"].to_numpy()\n",
    "                n_r_ref = r_ref.size\n",
    "            else:\n",
    "                # optional: skip curves with mismatched radial grid length\n",
    "                if sr.size != n_r_ref:\n",
    "                    continue\n",
    "\n",
    "            # c_norm quartiles (per-suite)\n",
    "            if c_quart_edges is not None and (idx in c_norm_map):\n",
    "                cn = c_norm_map[idx]\n",
    "                q_idx = assign_quartile(cn, c_quart_edges)\n",
    "                c_quart_slopes[q_idx].append(sr)\n",
    "                c_quart_vals[q_idx].append(cn)\n",
    "\n",
    "            # g_norm quartiles (per-suite)\n",
    "            if g_quart_edges is not None and (idx in g_norm_map):\n",
    "                gn = g_norm_map[idx]\n",
    "                q_idx = assign_quartile(gn, g_quart_edges)\n",
    "                g_quart_slopes[q_idx].append(sr)\n",
    "                g_quart_vals[q_idx].append(gn)\n",
    "\n",
    "    if r_ref is None:\n",
    "        print(\"[Warning] No valid slope data found.\")\n",
    "        return\n",
    "\n",
    "    def plot_quartiles(x, quart_slopes, quart_vals, fname, var_name):\n",
    "        plt.rcParams[\"text.usetex\"] = True\n",
    "        fig, ax = plt.subplots(figsize=(7, 5), dpi=600)\n",
    "\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.grid(which=\"both\", linestyle=\":\")\n",
    "        ax.axhline(-1.875, ls=\"--\", color=\"black\", lw=1, label=r\"$\\frac{d\\log Q_r}{d\\log r}=-1.875$\")\n",
    "        ax.set_xlim(6e-3, 1.1)\n",
    "        ax.set_ylim(-2.3, -1.2)\n",
    "        ax.set_xlabel(r\"$r / R_{\\rm vir}$\", fontsize=16)\n",
    "        ax.set_ylabel(r\"$d\\log Q_r / d\\log r$\", fontsize=16)\n",
    "        ax.tick_params(axis=\"both\", labelsize=12)\n",
    "\n",
    "        cmap = plt.cm.Greens\n",
    "        colors = [cmap(0.6), cmap(0.9)]   # only use lightest and darkest\n",
    "        labels = [\"Q1\", \"Q4\"]\n",
    "\n",
    "        for i, q in enumerate([0, 3]):   # only Q1 and Q4\n",
    "            Ys = quart_slopes[q]\n",
    "            vs = quart_vals[q]\n",
    "            if len(Ys) == 0:\n",
    "                ax.plot([], [], label=f\"{labels[i]} (N=0)\")\n",
    "                continue\n",
    "\n",
    "            Y = np.vstack(Ys)\n",
    "            mu = np.nanmean(Y, axis=0)\n",
    "            sd = np.nanstd(Y, axis=0)\n",
    "            vmean = float(np.nanmean(vs)) if len(vs) else np.nan\n",
    "\n",
    "            ax.fill_between(x, mu - sd, mu + sd, alpha=0.3, color=colors[i])\n",
    "            ax.plot(x, mu, lw=1.6, color=colors[i],\n",
    "                    label=fr\"${labels[i]}: \\langle {var_name} \\rangle= {vmean:.2f}$\")\n",
    "\n",
    "        ax.legend(loc='upper left', fontsize=11)\n",
    "        plt.tight_layout()\n",
    "        out_path = os.path.join(base_dir, 'figure', fname)\n",
    "        plt.savefig(out_path)\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "        \n",
    "    plot_quartiles(\n",
    "        r_ref, c_quart_slopes, c_quart_vals,\n",
    "        fname=\"ppsd_slope_r_split_cnorm_quartiles.pdf\",\n",
    "        var_name=r\"c_{\\mathrm{norm}}\"\n",
    "    )\n",
    "\n",
    "plot_ppsd_slope_split_by_quartiles_norm_vs_r_per_suite()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Astronomy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
